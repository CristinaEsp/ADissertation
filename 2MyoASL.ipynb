{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2MyoASL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNOc08I1fX7iTPtRBdJ7wGm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michelleaeh/Dissertation/blob/master/2MyoASL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH79ogCWrzbt",
        "colab_type": "text"
      },
      "source": [
        "**Myo armband dataset from https://data.mendeley.com/datasets/wgswcr8z24/2**\n",
        "\n",
        "\n",
        "**The dataset consits of .csv files collected from two Myo armbands. The format of the files are [word_name]_[id]. The ‘word_name’ is the English translation of the American Sign Language word used and the ‘id’ is a unique identifier. The .zip for each of the above links has sub-folders for each User.**\n",
        "\n",
        "**Each file has 50 columns. They represent a sub-sampled data collection from two Myo devices worn on left and right hands of the signer. The first column is the ‘Counter’ that goes from 1 to 50.**\n",
        "\n",
        "**The following columns are of the format: [Sensor][pod/direction][left/right]. For instance the EMG reading for the first EMG pod (out of 8) on the left hand would be called EMG0R and the accelerometer reading for the Z axis on the left hand would be called: AXL**\n",
        "\n",
        "**If you use this dataset please cite the following papers:**\n",
        "\n",
        "**@inproceedings{paudyal2016sceptre,\n",
        "title={Sceptre: a pervasive, non-invasive, and programmable gesture recognition technology},\n",
        "author={Paudyal, Prajwal and Banerjee, Ayan and Gupta, Sandeep KS},\n",
        "booktitle={Proceedings of the 21st International Conference on Intelligent User Interfaces},\n",
        "pages={282--293},\n",
        "year={2016},\n",
        "organization={ACM}\n",
        "}**\n",
        "\n",
        "**@inproceedings{paudyal2017dyfav,\n",
        "title={Dyfav: Dynamic feature selection and voting for real-time recognition of fingerspelled alphabet using wearables},\n",
        "author={Paudyal, Prajwal and Lee, Junghyo and Banerjee, Ayan and Gupta, Sandeep KS},\n",
        "booktitle={Proceedings of the 22nd International Conference on Intelligent User Interfaces},\n",
        "pages={457--467},\n",
        "year={2017},\n",
        "organization={ACM}\n",
        "}**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHNKWJHfhpMy",
        "colab_type": "text"
      },
      "source": [
        "**Frequency:**\n",
        "\n",
        "50Hz sampling rate\n",
        "\n",
        "**Words:**\n",
        "\n",
        "*36 total words*\n",
        "\n",
        "allmorning, bird, blue, cantsleep, cat, colrunnynose, continuouslyforanhour, cost, day, dollar, everymorning, everynight, gold, goodnight, happy, headache, home, horse, hot, hurt, itching, large, mom, monthly, notfeelgood, orange, pizza, please, shirt, soreness, swelling, takeliquidmedicine, thatsterrible, tired, upsetstomach, wash\n",
        "\n",
        "\n",
        "**Filenames:**\n",
        "\n",
        "*849 total files*\n",
        "\n",
        "(word)_(user#)(try#)\n",
        "\n",
        "\n",
        "**Columns of files:**\n",
        "\n",
        "Counter  (1 -> 50)\n",
        "\n",
        "EMG0L -> EMG7L  (EMG sensor readings)\n",
        "\n",
        "AXL, AYL, AZL  (accelerometer readings)\n",
        "\n",
        "GXL, GYL, GZL  (gyroscope readings)\n",
        "\n",
        "ORL, OPL, OYL  (magnetometer readings?)\n",
        "\n",
        "EMG0R -> EMG7R  (EMG sensor readings)\n",
        "\n",
        "AXR, AYR, AZR  (accelerometer readings)\n",
        "\n",
        "GXR, GYR, GZR  (gyroscope readings)\n",
        "\n",
        "ORR, OPR, OYR  (magnetometer readings?)\n",
        "\n",
        "features=['EMG0L', 'EMG1L', 'EMG2L', 'EMG3L', 'EMG4L', 'EMG5L', 'EMG6L', 'EMG7L', 'AXL', 'AYL', 'AZL', 'GXL', 'GYL', 'GZL', 'ORL', 'OPL', 'OYL', 'EMG0R', 'EMG1R', 'EMG2R', 'EMG3R', 'EMG4R', 'EMG5R', 'EMG6R', 'EMG7R', 'AXR', 'AYR', 'AZR', 'GXR', 'GYR', 'GZR', 'ORR', 'OPR', 'OYR']\n",
        "\n",
        "\n",
        "**Size of files:**\n",
        "\n",
        "All files are 50 rows x 35 columns except continuouslyforanhour_22.csv, headache_52.csv, home_61.csv, and mom_82.csv which are 101 rows x 35 columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TnTycFtrpHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import warnings\n",
        "\n",
        "from google.colab import files\n",
        "from mpl_toolkits import mplot3d\n",
        "from scipy import signal\n",
        "from scipy.io import loadmat\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Import zip containing all files\n",
        "file_name = \"/content/2MyoASL.zip\"\n",
        "\n",
        "# Extract all files from zip\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHsqsj2NRpEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate matrices for all combinations of sensors (E=3, A=5, G=7, O=11)\n",
        "products=[3, 5, 7, 11, 15, 21, 33, 35, 55, 77, 105, 165, 231, 385, 1155]\n",
        "comb=['e', 'a', 'g', 'o', 'ea', 'eg', 'eo', 'ag', 'ao', 'go', 'eag', 'eao', 'ego', 'ago', 'eago']\n",
        "emg=['EMG0L', 'EMG1L', 'EMG2L', 'EMG3L', 'EMG4L', 'EMG5L', 'EMG6L', 'EMG7L', \n",
        "    'EMG0R', 'EMG1R', 'EMG2R', 'EMG3R', 'EMG4R', 'EMG5R', 'EMG6R', 'EMG7R']\n",
        "acc=['AXL', 'AYL', 'AZL', 'AXR', 'AYR', 'AZR']\n",
        "gyro=['GXL', 'GYL', 'GZL', 'GXR', 'GYR', 'GZR']\n",
        "ori=['ORL', 'OPL', 'OYL', 'ORR', 'OPR', 'OYR']\n",
        "\n",
        "# Initialization of counters\n",
        "words=['allmorning', 'bird', 'blue', 'cantsleep', 'cat', 'coldrunnynose', 'continuouslyforanhour', 'cost', 'day', \n",
        "       'dollar', 'everymorning', 'everynight', 'gold', 'goodnight', 'happy', 'headache', 'home', 'horse', 'hot', \n",
        "       'hurt', 'itching', 'large', 'mom', 'monthly', 'notfeelgood', 'orange', 'pizza', 'please', 'shirt', \n",
        "       'soreness', 'swelling', 'takeliquidmedicine', 'thatsterrible', 'tired', 'upsetstomach', 'wash']\n",
        "lengths=np.zeros(849, dtype=int)\n",
        "reps=np.zeros(36,dtype=int)\n",
        "features=np.zeros(15)\n",
        "target=np.zeros(15)\n",
        "\n",
        "fn=np.arange(35)\n",
        "wordnum=-1\n",
        "counter=0\n",
        "n=0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQFtofv7yG7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "0fc967f0-957b-454f-afae-d00f169382af"
      },
      "source": [
        "# Combine all files\n",
        "for w in words:\n",
        "  repcount=0\n",
        "  wordnum+=1\n",
        "\n",
        "  for i in range (10, 120):\n",
        "    path='/content/2MyoASL/' + w + '_' + str(i) + '.csv'\n",
        "\n",
        "    if os.path.exists(path)==True:\n",
        "      counter+=1\n",
        "      repcount+=1\n",
        "      trial=pd.read_csv(path)\n",
        "      lengths[counter-1]=len(trial)\n",
        "\n",
        "      # Replace counter with evaluated term\n",
        "      trial['Word']=wordnum\n",
        "      #####################for r in range(0,len(trial)):\n",
        "      #####################  trial.iloc[r,0]=wordnum\n",
        "      #trial.groupby('Counter')\n",
        "      ####trial=trial.set_index([pd.Index(range(len(trial))), 'Counter'], append=True).swaplevel(0,1)\n",
        "      #trial.iloc[0,0]=wordnum\n",
        "      #####################trial=trial.set_index('Counter', append=True).swaplevel(0,1)\n",
        "      trial.set_index(['Word','Counter'], inplace=True)\n",
        "      \n",
        "      # Combine all trials\n",
        "      if path=='/content/2MyoASL/allmorning_10.csv':\n",
        "          matrix=trial\n",
        "      else:\n",
        "          #matrix=pd.concat([matrix, trial],keys=[wordnum])\n",
        "          matrix=pd.concat([matrix,trial])\n",
        "\"\"\"\n",
        "      # Plot\n",
        "      if i==10:\n",
        "        # Create plot for EMG\n",
        "        emgp, axs=plt.subplots(16,figsize=(30,30))\n",
        "        for z in emg:\n",
        "          emgp.suptitle('EMG for ' + w)\n",
        "          axs[emg.index(z)].plot(trial.loc[:, z].values)\n",
        "        \n",
        "        # Create plot for accelerometer\n",
        "        plt.figure()\n",
        "        alx=plt.axes(projection='3d')\n",
        "        alx.plot3D(trial.loc[:, 'AXL'].values, trial.loc[:, 'AYL'].values, trial.loc[:, 'AZL'].values)\n",
        "        alx.set_title('Accelerometer on left arm for '+w)\n",
        "\n",
        "        plt.figure()\n",
        "        arx=plt.axes(projection='3d')\n",
        "        arx.plot3D(trial.loc[:, 'AXR'].values, trial.loc[:, 'AYR'].values, trial.loc[:, 'AZR'].values)\n",
        "        arx.set_title('Accelerometer on right arm for '+w)\n",
        "\n",
        "        # Create plot for gyroscope\n",
        "        plt.figure()\n",
        "        glx=plt.axes(projection='3d')\n",
        "        glx.plot3D(trial.loc[:, 'GXL'].values, trial.loc[:, 'GYL'].values, trial.loc[:, 'GZL'].values)\n",
        "        glx.set_title('Gyroscope on left arm for '+w)\n",
        "\n",
        "        plt.figure()\n",
        "        grx=plt.axes(projection='3d')\n",
        "        grx.plot3D(trial.loc[:, 'GXR'].values, trial.loc[:, 'GYR'].values, trial.loc[:, 'GZR'].values)\n",
        "        grx.set_title('Gyroscope on right arm for '+w)\n",
        "\n",
        "        # Create plot for orientation\n",
        "        orip, axt=plt.subplots(6,figsize=(30,30))\n",
        "        for f in ori:\n",
        "          orip.suptitle('Orientation for ' + w)\n",
        "          axt[ori.index(f)].plot(trial.loc[:, f].values)\n",
        "\n",
        "      else:\n",
        "        # Plot EMG\n",
        "        for z in emg:\n",
        "          axs[emg.index(z)].plot(trial.loc[:, z].values)\n",
        "        \n",
        "        # Plot accelerometer\n",
        "        alx.plot3D(trial.loc[:, 'AXL'].values, trial.loc[:, 'AYL'].values, trial.loc[:, 'AZL'].values)\n",
        "        arx.plot3D(trial.loc[:, 'AXR'].values, trial.loc[:, 'AYR'].values, trial.loc[:, 'AZR'].values)\n",
        "        \n",
        "        # Plot gyroscope\n",
        "        glx.plot3D(trial.loc[:, 'GXL'].values, trial.loc[:, 'GYL'].values, trial.loc[:, 'GZL'].values)\n",
        "        grx.plot3D(trial.loc[:, 'GXR'].values, trial.loc[:, 'GYR'].values, trial.loc[:, 'GZR'].values)\n",
        "          \n",
        "        # Plot orientation\n",
        "        for f in ori:\n",
        "          axt[ori.index(f)].plot(trial.loc[:, f].values)\n",
        "        \n",
        "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
        "  reps[wordnum]=repcount\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "\"\"\"\n",
        "print(matrix)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              EMG0L  EMG1L  EMG2L  EMG3L  ...       GZR  ORR  OPR  OYR\n",
            "Word Counter                              ...                         \n",
            "0    1            0      0      0      0  ...    6.3750   84  104   84\n",
            "     2            0      0      0      0  ...   21.3750   84  105   84\n",
            "     3           -3     -1      5      9  ...   26.6250   87  106   85\n",
            "     4           -1     13      9      5  ...   70.5000   88  101   86\n",
            "     5          -31    -10      2     11  ...  118.1250   93   87   89\n",
            "...             ...    ...    ...    ...  ...       ...  ...  ...  ...\n",
            "35   46          -2     -1     -4     -1  ...  -82.9375  104  105  179\n",
            "     47           0     -3      0     -1  ...  -56.1875  103  113  179\n",
            "     48          -1      3      0      0  ...  -15.5625  103  118  179\n",
            "     49           1      4      1      0  ...   -3.3750  103  120  179\n",
            "     50          -1      0     -1     -3  ...    6.2500  102  120    0\n",
            "\n",
            "[42654 rows x 34 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7Ib41KW5f32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eliminate unnecessary columns to create combinatory matrices\n",
        "for v in products:\n",
        "  m=matrix\n",
        "  if v%3!=0:\n",
        "    m=m.drop(emg,1)\n",
        "  if v%5!=0:\n",
        "    m=m.drop(acc,1)\n",
        "  if v%7!=0:\n",
        "    m=m.drop(gyro,1)\n",
        "  if v%11!=0:\n",
        "    m=m.drop(ori,1)\n",
        "  products[n]=m\n",
        "  exec(comb[n]+\"=products[n]\")\n",
        "  n+=1\n",
        "  \n",
        "  # Normalize and Standardize each of the 15 matrices\n",
        "  # Separate features from target values\n",
        "  x = m.loc[:, m.columns].values   # Features\n",
        "  ######################y = m.loc[:,'Counter'].values               # Target\n",
        "  ####y = m.index[m['Word']]\n",
        "\n",
        "  #y=m.iloc[0]\n",
        "  #\"None of [Index(['Counter'], dtype='object')] are in the [columns]\"\n",
        "\n",
        "  ## Normalize features so that each column is between 0 and 1\n",
        "  norm_matrix=(m-m.min())/(m.max()-m.min())\n",
        "  exec(\"norm_matrix_\"+comb[n-1]+\"=pd.DataFrame(norm_matrix)\")\n",
        "\n",
        "  # Normalize features\n",
        "#  normalized_matrix=(x-x.min())/(x.max()-x.min())\n",
        "#  exec(\"normalized_matrix_\"+comb[n-1]+\"=pd.DataFrame(normalized_matrix)\")\n",
        "\n",
        "  # Standardize features with mean=0 and deviation=1\n",
        "  standardized_matrix=StandardScaler().fit_transform(x)\n",
        "  exec(\"standardized_matrix_\"+comb[n-1]+\"=pd.DataFrame(standardized_matrix)\")\n",
        "\n",
        "  # Save data frames as csv files\n",
        "  #matrix.to_csv(path_or_buf='/content/matrix_'+comb[n-1]+'.csv')\n",
        "  exec(\"norm_matrix_\"+comb[n-1]+\".to_csv(path_or_buf='/content/normmatrix_'+comb[n-1]+'.csv')\")\n",
        "#  exec(\"normalized_matrix_\"+comb[n-1]+\".to_csv(path_or_buf='/content/normalizedmatrix_'+comb[n-1]+'.csv')\")\n",
        "  exec(\"standardized_matrix_\"+comb[n-1]+\".to_csv(path_or_buf='/content/standardizedmatrix_'+comb[n-1]+'.csv')\")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJjGC_1Q5r03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Butterworth\n",
        "#high = 20/(1000/2)\n",
        "#low = 450/(1000/2)\n",
        "high = 1/(50/2)\n",
        "low = 23/(50/2)\n",
        "\n",
        "b, a = sp.signal.butter(4, [high,low], btype='bandpass')\n",
        "\n",
        "for r in emg:\n",
        "  norm_matrix_eago[[r]]\n",
        "  # process EMG signal: filter EMG\n",
        "  emg_filtered = sp.signal.lfilter(b, a, norm_matrix_eago[[r]])\n",
        "  norm_matrix_eago[[r]]=emg_filtered"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufJX_eg5fmXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_top=norm_matrix_eago.head()\n",
        "#list(data_top.index.values)\n",
        "indices=list(norm_matrix_eago.index.values.tolist()) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riv-kFwa9oMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "4887b494-597a-4c65-a91d-a6126271d6b2"
      },
      "source": [
        "# PCA for norm_matrix\n",
        "norm_matrix_eago.reset_index(drop=True, inplace=True)\n",
        "m.reset_index(drop=True, inplace=True)\n",
        "\n",
        "x = norm_matrix_eago.loc[:, norm_matrix_eago.columns != 'Counter'].values   # Features\n",
        "y = m.loc[:,['Counter']].values               # Target\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6, random_state=0)\n",
        "\n",
        "pca = PCA(n_components=30)\n",
        "pca.fit(x_train)\n",
        "x_t_train = pca.transform(x_train)\n",
        "x_t_test = pca.transform(x_test)\n",
        "\n",
        "#### plot\n",
        "print(\"Normalized matrix\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn,pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn,pca.singular_values_)\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5502edffb46f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_matrix_eago\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_matrix_eago\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Counter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m   \u001b[0;31m# Features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Counter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m               \u001b[0;31m# Target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1287\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         )\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1638\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Counter'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESPNzdyghacn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM\n",
        "clf = SVC()\n",
        "clf.fit(x_t_train, y_train)\n",
        "print ('score', clf.score(x_t_test, y_test))\n",
        "print ('pred label', clf.predict(x_t_test))\n",
        "print('length',len(clf.predict(x_t_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSevZSPDFZjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, x_t_test, y_test,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.figure(figsize=(500,500))\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "#Accuracy, sensitivity and specificity\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm1 = confusion_matrix(Fiber_df[['active_cust']],predicted_class1)\n",
        "print('Confusion Matrix : \\n', cm1)\n",
        "\n",
        "total1=sum(sum(cm1))\n",
        "#####from confusion matrix calculate accuracy\n",
        "accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
        "print ('Accuracy : ', accuracy1)\n",
        "\n",
        "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "print('Sensitivity : ', sensitivity1 )\n",
        "\n",
        "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "print('Specificity : ', specificity1)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h57zKLByfy2Y",
        "colab_type": "text"
      },
      "source": [
        "TODO:\n",
        "\n",
        "-check what happens when combining diff data sources\n",
        "\n",
        "-graph components\n",
        "\n",
        "find correlations\n",
        "\n",
        "interpret pca results\n",
        "\n",
        "-try pca per individual/word\n",
        "\n",
        "-read dataset papers\n",
        "\n",
        "correlation component with word\n",
        "\n",
        "try stright to svm\n",
        "\n",
        "resend email\n",
        "\n",
        "check what is the data\n",
        "\n",
        "merge timeseries word index\n",
        "\n",
        "see how stable each feature are\n",
        "\n",
        "standard deviation timeseries\n",
        "\n",
        "try without filter\n",
        "\n",
        "multi-class classifier SVM\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScbnguG8ONoC",
        "colab_type": "text"
      },
      "source": [
        "https://www.researchgate.net/publication/303707429_Combining_Smartphone_and_Smartwatch_Sensor_Data_in_Activity_Recognition_Approaches_an_Experimental_Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay3NExQ59xrM",
        "colab_type": "text"
      },
      "source": [
        "References\n",
        "\n",
        "https://stackoverflow.com/questions/56449262/how-to-upload-folders-to-google-colab\n",
        "\n",
        "https://github.com/datarail/datarail/issues/39\n",
        "\n",
        "https://dbader.org/blog/python-check-if-file-exists\n",
        "\n",
        "https://datacarpentry.org/python-socialsci/11-joins/index.html\n",
        "\n",
        "https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
        "\n",
        "https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
        "\n",
        "https://www.tutorialspoint.com/matplotlib/matplotlib_bar_plot.htm\n",
        "\n",
        "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.signal.butter.html\n",
        "\n",
        "https://stackoverflow.com/questions/32194967/how-to-do-pca-and-svm-for-classification-in-python\n",
        "\n",
        "https://stackoverflow.com/questions/6822725/rolling-or-sliding-window-iterator\n",
        "\n",
        "https://scikit-learn.org/stable/modules/cross_validation.html\n",
        "\n",
        "https://stackoverflow.com/questions/47684606/merge-cells-with-pandas\n",
        "\n",
        "https://scientificallysound.org/2016/08/18/python-analysing-emg-signals-part-3/\n",
        "\n",
        "https://stackoverflow.com/questions/58374492/python-valueerror-the-length-of-the-input-vector-x-must-be-greater-than-padle\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html\n",
        "\n",
        "https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "https://statinfer.com/204-4-2-calculating-sensitivity-and-specificity-in-python/\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/pandas-multi-index\n",
        "\n",
        "https://www.geeksforgeeks.org/how-to-get-rows-index-names-in-pandas-dataframe/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V77MeC59AHdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "### Combine all files\n",
        "words=['allmorning', 'bird', 'blue', 'cantsleep', 'cat', 'coldrunnynose', 'continuouslyforanhour', 'cost', 'day', 'dollar', 'everymorning', 'everynight', 'gold', 'goodnight', 'happy', 'headache', 'home', 'horse', 'hot', 'hurt', 'itching', 'large', 'mom', 'monthly', 'notfeelgood', 'orange', 'pizza', 'please', 'shirt', 'soreness', 'swelling', 'takeliquidmedicine', 'thatsterrible', 'tired', 'upsetstomach', 'wash']\n",
        "lengths=np.zeros(849, dtype=int)\n",
        "reps=np.zeros(36,dtype=int)\n",
        "wordnum=-1\n",
        "counter=0\n",
        "\n",
        "for w in words:\n",
        "  repcount=0\n",
        "  wordnum+=1\n",
        "\n",
        "  for i in range (10, 120):\n",
        "    path='/content/2MyoASL/' + w + '_' + str(i) + '.csv'\n",
        "\n",
        "    if os.path.exists(path)==True:\n",
        "      counter+=1\n",
        "      repcount+=1\n",
        "      trial=pd.read_csv(path)\n",
        "      lengths[counter-1]=len(trial)\n",
        "      \n",
        "      # Replace counter with evaluated term\n",
        "      for r in range(0,len(trial)):\n",
        "        trial.iloc[r,0]=wordnum\n",
        "        \n",
        "      # Combine all trials\n",
        "      if path=='/content/2MyoASL/allmorning_10.csv':\n",
        "          matrix=trial\n",
        "          \n",
        "          # Create plot for EMG\n",
        "\n",
        "          # Create plot for accelerometer\n",
        "          plt.figure()\n",
        "          alx=plt.axes(projection='3d')\n",
        "          alx.plot3D(trial.loc[:, 'AXL'].values, trial.loc[:, 'AYL'].values, trial.loc[:, 'AZL'].values)\n",
        "          alx.set_title('Accelerometer on left arm')\n",
        "\n",
        "          plt.figure()\n",
        "          arx=plt.axes(projection='3d')\n",
        "          arx.plot3D(trial.loc[:, 'AXR'].values, trial.loc[:, 'AYR'].values, trial.loc[:, 'AZR'].values)\n",
        "          arx.set_title('Accelerometer on right arm')\n",
        "\n",
        "          # Create plot for gyroscope\n",
        "          plt.figure()\n",
        "          glx=plt.axes(projection='3d')\n",
        "          glx.plot3D(trial.loc[:, 'GXL'].values, trial.loc[:, 'GYL'].values, trial.loc[:, 'GZL'].values)\n",
        "          glx.set_title('Gyroscope on left arm')\n",
        "\n",
        "          plt.figure()\n",
        "          grx=plt.axes(projection='3d')\n",
        "          grx.plot3D(trial.loc[:, 'GXR'].values, trial.loc[:, 'GYR'].values, trial.loc[:, 'GZR'].values)\n",
        "          grx.set_title('Gyroscope on right arm')\n",
        "      else:\n",
        "          matrix=pd.concat([matrix, trial])\n",
        "\n",
        "          ###############################################\n",
        "          # Create plot for accelerometer\n",
        "          alx.plot3D(trial.loc[:, 'AXL'].values, trial.loc[:, 'AYL'].values, trial.loc[:, 'AZL'].values)\n",
        "          arx.plot3D(trial.loc[:, 'AXR'].values, trial.loc[:, 'AYR'].values, trial.loc[:, 'AZR'].values)\n",
        "          #plt.show()\n",
        "\n",
        "          # Create plot for gyroscope\n",
        "          glx.plot3D(trial.loc[:, 'GXL'].values, trial.loc[:, 'GYL'].values, trial.loc[:, 'GZL'].values)\n",
        "          grx.plot3D(trial.loc[:, 'GXR'].values, trial.loc[:, 'GYR'].values, trial.loc[:, 'GZR'].values)\n",
        "          ###############################################\n",
        "\n",
        "  reps[wordnum]=repcount\n",
        "plt.show()\n",
        "\"\"\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knhJG10SD22U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "# PCA for normmatrix\n",
        "pca = PCA(n_components=35)\n",
        "comp=pca.fit_transform(norm_matrix_eago)\n",
        "principal=pd.DataFrame(data=comp, columns=['PC 0', 'PC 1', 'PC 2', 'PC 3', 'PC 4', 'PC 5', 'PC 6', 'PC 7', 'PC 8', 'PC 9', 'PC 10', \n",
        "                                           'PC 11', 'PC 12', 'PC 13', 'PC 14', 'PC 16', 'PC 17', 'PC 18', 'PC 19', 'PC 20', \n",
        "                                           'PC 21', 'PC 22', 'PC 23', 'PC 24', 'PC 25', 'PC 26', 'PC 27', 'PC 28', 'PC 29', \n",
        "                                           'PC 30', 'PC 31', 'PC 32', 'PC 33', 'PC 34', 'PC35'])\n",
        "#principal.reset_index(drop=True, inplace=True)\n",
        "#norm_matrix_eago[['Counter']].reset_index(drop=True, inplace=True)\n",
        "norm_matrix_eago.reset_index(drop=True, inplace=True)\n",
        "m.reset_index(drop=True, inplace=True)\n",
        "#finaldf=pd.join([principal, norm_matrix_eago[['Counter']]], axis=1, ignore_index=True).reset_index()\n",
        "finaldf=principal.join(m[['Counter']],how='outer')\n",
        "finaldf=finaldf.drop(columns=['PC 0'])\n",
        "####finaldf=principal\n",
        "####print(m['Counter'])\n",
        "####finaldf['Word']=m['Counter']\n",
        "#finaldf=pd.concat([principal,norm_matrix_eago[['Counter']]], axis=1, ignore_index=True)\n",
        "\n",
        "print(\"Normalized matrix\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn,pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn,pca.singular_values_)\n",
        "plt.show()\n",
        "print(finaldf)\n",
        "#print(principal.join(norm_matrix_eago[['Counter']],how='inner'))\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "# PCA for normalizedmatrix\n",
        "pca = PCA(n_components=34)\n",
        "pca.fit(normalized_matrix)\n",
        "print(\"Normalized features\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn[0:34],pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn[0:34],pca.singular_values_)\n",
        "plt.show()\n",
        "\n",
        "# PCA for standardizedmatrix\n",
        "pca = PCA(n_components=34)\n",
        "pca.fit(standardized_matrix)\n",
        "print(\"Standardized features\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn[0:34],pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn[0:34],pca.singular_values_)\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}