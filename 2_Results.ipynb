{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-Results",
      "provenance": [],
      "collapsed_sections": [
        "8jLxiAwpHUrt",
        "Gca7rp-1Gimq",
        "yJtV04hjOid6",
        "hK_pmaOQrYOu",
        "wyBtMxHArsn5"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michelleaeh/ADissertation/blob/master/2_Results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dcws6GC7s8aT",
        "colab_type": "text"
      },
      "source": [
        "**Project:** MSc in Robotics and Intelligent Systems Dissertation\n",
        "\n",
        "**Project name:**\n",
        "\n",
        "**Author:** Michelle Alejandra Espinosa Hernandez\n",
        "\n",
        "**Student registration number:** 1900964\n",
        "\n",
        "**Student PRID:** ESPIN62803\n",
        "\n",
        "**Date created:** \n",
        "\n",
        "**Purpose:** Obtain classification accuracy among different types of sensors and different data processing steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jLxiAwpHUrt",
        "colab_type": "text"
      },
      "source": [
        "# **Data description**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH79ogCWrzbt",
        "colab_type": "text"
      },
      "source": [
        "**Myo armband dataset from https://data.mendeley.com/datasets/wgswcr8z24/2**\n",
        "\n",
        "\n",
        "The dataset consits of .csv files collected from two Myo armbands. The format of the files are [word_name]_[id]. The ‘word_name’ is the English translation of the American Sign Language word used and the ‘id’ is a unique identifier. The .zip for each of the above links has sub-folders for each User.\n",
        "\n",
        "Each file has 50 columns. They represent a sub-sampled data collection from two Myo devices worn on left and right hands of the signer. The first column is the ‘Counter’ that goes from 1 to 50.\n",
        "\n",
        "The following columns are of the format: [Sensor][pod/direction][left/right]. For instance the EMG reading for the first EMG pod (out of 8) on the left hand would be called EMG0R and the accelerometer reading for the Z axis on the left hand would be called: AXL\n",
        "\n",
        "If you use this dataset please cite the following papers:\n",
        "\n",
        "@inproceedings{paudyal2016sceptre,\n",
        "title={Sceptre: a pervasive, non-invasive, and programmable gesture recognition technology},\n",
        "author={Paudyal, Prajwal and Banerjee, Ayan and Gupta, Sandeep KS},\n",
        "booktitle={Proceedings of the 21st International Conference on Intelligent User Interfaces},\n",
        "pages={282--293},\n",
        "year={2016},\n",
        "organization={ACM}\n",
        "}\n",
        "\n",
        "@inproceedings{paudyal2017dyfav,\n",
        "title={Dyfav: Dynamic feature selection and voting for real-time recognition of fingerspelled alphabet using wearables},\n",
        "author={Paudyal, Prajwal and Lee, Junghyo and Banerjee, Ayan and Gupta, Sandeep KS},\n",
        "booktitle={Proceedings of the 22nd International Conference on Intelligent User Interfaces},\n",
        "pages={457--467},\n",
        "year={2017},\n",
        "organization={ACM}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHNKWJHfhpMy",
        "colab_type": "text"
      },
      "source": [
        "**Frequency:**\n",
        "\n",
        "50Hz sampling rate\n",
        "\n",
        "**Words:**\n",
        "\n",
        "*36 total words*\n",
        "\n",
        "allmorning, bird, blue, cantsleep, cat, colrunnynose, continuouslyforanhour, cost, day, dollar, everymorning, everynight, gold, goodnight, happy, headache, home, horse, hot, hurt, itching, large, mom, monthly, notfeelgood, orange, pizza, please, shirt, soreness, swelling, takeliquidmedicine, thatsterrible, tired, upsetstomach, wash\n",
        "\n",
        "\n",
        "**Filenames:**\n",
        "\n",
        "*849 total files*\n",
        "\n",
        "(word)_(user#)(try#)\n",
        "\n",
        "\n",
        "**Columns of files:**\n",
        "\n",
        "Counter  (1 -> 50)\n",
        "\n",
        "EMG0L -> EMG7L  (EMG sensor readings)\n",
        "\n",
        "AXL, AYL, AZL  (accelerometer readings)\n",
        "\n",
        "GXL, GYL, GZL  (gyroscope readings)\n",
        "\n",
        "ORL, OPL, OYL  (magnetometer readings?)\n",
        "\n",
        "EMG0R -> EMG7R  (EMG sensor readings)\n",
        "\n",
        "AXR, AYR, AZR  (accelerometer readings)\n",
        "\n",
        "GXR, GYR, GZR  (gyroscope readings)\n",
        "\n",
        "ORR, OPR, OYR  (magnetometer readings?)\n",
        "\n",
        "features=['EMG0L', 'EMG1L', 'EMG2L', 'EMG3L', 'EMG4L', 'EMG5L', 'EMG6L', 'EMG7L', 'AXL', 'AYL', 'AZL', 'GXL', 'GYL', 'GZL', 'ORL', 'OPL', 'OYL', 'EMG0R', 'EMG1R', 'EMG2R', 'EMG3R', 'EMG4R', 'EMG5R', 'EMG6R', 'EMG7R', 'AXR', 'AYR', 'AZR', 'GXR', 'GYR', 'GZR', 'ORR', 'OPR', 'OYR']\n",
        "\n",
        "\n",
        "**Size of files:**\n",
        "\n",
        "All files are 50 rows x 35 columns except continuouslyforanhour_22.csv, headache_52.csv, home_61.csv, and mom_82.csv which are 101 rows x 35 columns\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. Combine files\n",
        "2. Normalize or standardize matrix\n",
        "3. Apply Butterworth\n",
        "4. Apply PCA\n",
        "5. Input to SVM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gca7rp-1Gimq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# **1. Preparation of data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXI1GgkfFdai",
        "colab_type": "text"
      },
      "source": [
        "**1.1. Start up and initialization of variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TnTycFtrpHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import timeit\n",
        "start = timeit.default_timer()\n",
        "\n",
        "from collections import Counter\n",
        "from google.colab import files\n",
        "from mpl_toolkits import mplot3d\n",
        "from scipy import signal\n",
        "from scipy.io import loadmat\n",
        "from sklearn import metrics\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Extract all files from zip\n",
        "with ZipFile(\"/content/2MyoASL.zip\", 'r') as zip:\n",
        "  zip.extractall()\n",
        "\n",
        "products=[3, 5, 7, 11, 15, 21, 33, 35, 55, 77, 105, 165, 231, 385, 1155] # Generate matrices for all combinations of sensors (E=3, A=5, G=7, O=11)\n",
        "steps=[13, 39, 65, 91, 143, 273, 429, 455, 715, 1001, 3003, 5005] # Generate matrices for all combinations of steps (Normalization=3, Standardization=5, Butterworth=7, PCA=11, SVM=13)\n",
        "comb=['E', 'A', 'G', 'O', 'EA', 'EG', 'EO', 'AG', 'AO', 'GO', 'EAG', 'EAO', 'EGO', 'AGO', 'EAGO'] # Generate matrices for all combinations of sensors (E=emg, A=acc, G=gyro, O=ori)\n",
        "nsteps=['V', 'NV', 'SV', 'BV', 'PV', 'NBV', 'NPV', 'SBV', 'SPV', 'BPV', 'NBPV', 'SBPV'] # Generate matrices for all combinations of steps (N=Normalization, S=Standardization, B=Butterworth, P=PCA, V=SVM)\n",
        "emg=['EMG0L', 'EMG1L', 'EMG2L', 'EMG3L', 'EMG4L', 'EMG5L', 'EMG6L', 'EMG7L', \n",
        "     'EMG0R', 'EMG1R', 'EMG2R', 'EMG3R', 'EMG4R', 'EMG5R', 'EMG6R', 'EMG7R']\n",
        "acc=['AXL', 'AYL', 'AZL', 'AXR', 'AYR', 'AZR']\n",
        "gyro=['GXL', 'GYL', 'GZL', 'GXR', 'GYR', 'GZR']\n",
        "ori=['ORL', 'OPL', 'OYL', 'ORR', 'OPR', 'OYR']\n",
        "\n",
        "# Initialization of counters\n",
        "words=['allmorning', 'bird', 'blue', 'cantsleep', 'cat', 'coldrunnynose', 'continuouslyforanhour', 'cost', 'day', \n",
        "       'dollar', 'everymorning', 'everynight', 'gold', 'goodnight', 'happy', 'headache', 'home', 'horse', 'hot', \n",
        "       'hurt', 'itching', 'large', 'mom', 'monthly', 'notfeelgood', 'orange', 'pizza', 'please', 'shirt', \n",
        "       'soreness', 'swelling', 'takeliquidmedicine', 'thatsterrible', 'tired', 'upsetstomach', 'wash']\n",
        "colnames=emg[:8]+acc[:3]+gyro[:3]+ori[:3]+emg[8:]+acc[3:]+gyro[3:]+ori[3:]\n",
        "lengths=np.zeros(849, dtype=int)\n",
        "reps=np.zeros(36,dtype=int)\n",
        "repsum=np.zeros(37,dtype=int)\n",
        "headers=np.empty(1701, dtype=object)\n",
        "fresults=np.zeros((len(steps),len(products)))\n",
        "params=np.zeros((len(steps),len(products)))\n",
        "features=np.zeros(15)\n",
        "target=np.zeros(15)\n",
        "matrix=np.zeros(1)\n",
        "norm=[]\n",
        "stand=[]\n",
        "\n",
        "fn=np.arange(1701)\n",
        "wordnum=-1\n",
        "counter=-1\n",
        "rownum=-1\n",
        "start=0\n",
        "num=0\n",
        "n=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAKRziACFoe0",
        "colab_type": "text"
      },
      "source": [
        "**1.2. Combine all files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQFtofv7yG7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "de8fc1cd-4c19-418e-de35-3339e45734e9"
      },
      "source": [
        "for w in words:\n",
        "  repcount=0\n",
        "  wordnum+=1\n",
        "  for i in range (10, 120):\n",
        "    path='/content/2MyoASL/' + w + '_' + str(i) + '.csv'\n",
        "    if os.path.exists(path)==True:\n",
        "      counter+=1\n",
        "      repcount+=1\n",
        "      trial=pd.read_csv(path)\n",
        "      trial.reset_index(drop=True)\n",
        "      \n",
        "      # Assign word number to one row\n",
        "      row=np.zeros(1)\n",
        "      for t in range(35):\n",
        "        if t==0:\n",
        "          row[0]=wordnum\n",
        "        else:\n",
        "          sensor=trial.iloc[0:50,t].values\n",
        "          sensor.reshape([1,50])\n",
        "          row=np.concatenate((row, sensor))\n",
        "      prev=row\n",
        "      \n",
        "      # Combine all trials\n",
        "      if counter==0:\n",
        "        matrix=prev\n",
        "      else:\n",
        "        matrix=np.concatenate([matrix,prev])\n",
        "\n",
        "  reps[wordnum]=repcount\n",
        "  if wordnum>0:\n",
        "    repsum[wordnum]=reps[wordnum-1]+repsum[wordnum-1]\n",
        "    repsum[36]=849\n",
        "\n",
        "# Create header name array\n",
        "headers[0]='Word'\n",
        "for c in colnames:\n",
        "  for t in range(50):\n",
        "    num+=1\n",
        "    headers[num]=c\n",
        "\n",
        "# Give format to final matrix \n",
        "matrix=matrix.reshape([849,1701])\n",
        "matrix=pd.DataFrame(matrix, columns=headers)\n",
        "print(matrix)\n",
        "print('Reps of each word:',reps)\n",
        "print('Cummulative reps:',repsum)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Word  EMG0L  EMG0L  EMG0L  EMG0L  ...    OYR    OYR    OYR    OYR    OYR\n",
            "0     0.0    0.0    0.0   -3.0   -1.0  ...   83.0   83.0   83.0   83.0   83.0\n",
            "1     0.0    0.0    0.0    4.0   -2.0  ...   83.0   83.0   83.0   83.0   83.0\n",
            "2     0.0    0.0    0.0   -8.0   -1.0  ...   84.0   84.0   84.0   84.0   84.0\n",
            "3     0.0    0.0    0.0   -1.0  -19.0  ...   83.0   83.0   83.0   83.0   83.0\n",
            "4     0.0    0.0    0.0    1.0  -16.0  ...   93.0   91.0   91.0   91.0   91.0\n",
            "..    ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
            "844  35.0    0.0    0.0   -2.0    0.0  ...  106.0  104.0  100.0   98.0   95.0\n",
            "845  35.0    0.0    0.0    2.0   -8.0  ...  176.0  176.0  177.0  177.0  177.0\n",
            "846  35.0    0.0    0.0   -8.0   26.0  ...  177.0  176.0  175.0  175.0  176.0\n",
            "847  35.0    0.0    0.0   -1.0   21.0  ...  178.0  178.0  179.0  179.0  179.0\n",
            "848  35.0    0.0    0.0    8.0  -19.0  ...  179.0  179.0  179.0  179.0    0.0\n",
            "\n",
            "[849 rows x 1701 columns]\n",
            "Reps of each word: [19 24 32 20 24 20 19 31 24 29 20 21 23 33 34 18 27 24 35 19 17 34 30 19\n",
            " 22 21 23 27 27  4 20 19 20 20 21 29]\n",
            "Cummulative reps: [  0  19  43  75  95 119 139 158 189 213 242 262 283 306 339 373 391 418\n",
            " 442 477 496 513 547 577 596 618 639 662 689 716 720 740 759 779 799 820\n",
            " 849]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaKAX2XvGL3O",
        "colab_type": "text"
      },
      "source": [
        "**1.3. Calculate mean and standard deviation of each sensor and each file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaytNKUWGo7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "d1cd90e5-d08d-48c0-f025-a849f1781517"
      },
      "source": [
        "# Average and standard deviation of each sensor in each file\n",
        "for s in colnames:\n",
        "  avg=matrix[s].mean(axis=1)\n",
        "  sd=matrix[s].std(axis=1)\n",
        "  sensor=pd.concat([avg.rename(s+': Mean_'),sd.rename('St. dev.')], axis=1)\n",
        "  if s=='EMG0L':\n",
        "    asd=sensor\n",
        "  else:\n",
        "    asd=pd.concat([asd, sensor], axis=1)\n",
        "print(asd)\n",
        "\n",
        "# Average and standard deviation of each file\n",
        "avg=matrix.mean(axis=1)\n",
        "sd=matrix.std(axis=1)\n",
        "pd.concat([avg.rename('Mean'),sd.rename('St. dev.')], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     EMG0L: Mean_   St. dev.  EMG1L: Mean_  ...   St. dev.  OYR: Mean_   St. dev.\n",
            "0           -2.32   8.664825         -0.80  ...  28.427609       86.70  10.529356\n",
            "1           -1.80   9.544739         -4.08  ...  27.821010       85.68   6.579002\n",
            "2           -3.16  13.085839         -2.32  ...  30.345736       91.88  17.358924\n",
            "3           -0.82  10.123099         -3.16  ...  29.645002       88.46  12.969682\n",
            "4           -0.50   6.516071          2.76  ...  13.237239      116.58  18.099600\n",
            "..            ...        ...           ...  ...        ...         ...        ...\n",
            "844          0.56   7.754288          0.22  ...  17.236281      104.76   7.528341\n",
            "845         -1.74   6.520955         -1.20  ...  21.772891       69.66  85.251036\n",
            "846          1.02   7.731436          0.46  ...  22.707735       56.76  79.408415\n",
            "847          0.06   5.582078          2.36  ...  23.650422       71.62  84.238701\n",
            "848         -2.22   7.434860         -1.62  ...  25.101622       58.52  79.668763\n",
            "\n",
            "[849 rows x 68 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean</th>\n",
              "      <th>St. dev.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.256437</td>\n",
              "      <td>46.545832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.220110</td>\n",
              "      <td>47.316822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15.441784</td>\n",
              "      <td>45.614456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.651092</td>\n",
              "      <td>47.038916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15.063294</td>\n",
              "      <td>49.105612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>844</th>\n",
              "      <td>13.167964</td>\n",
              "      <td>41.642351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>13.815314</td>\n",
              "      <td>42.880121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>12.970618</td>\n",
              "      <td>42.725653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>13.852317</td>\n",
              "      <td>43.758631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>13.144035</td>\n",
              "      <td>44.761750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>849 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Mean   St. dev.\n",
              "0    15.256437  46.545832\n",
              "1    14.220110  47.316822\n",
              "2    15.441784  45.614456\n",
              "3    13.651092  47.038916\n",
              "4    15.063294  49.105612\n",
              "..         ...        ...\n",
              "844  13.167964  41.642351\n",
              "845  13.815314  42.880121\n",
              "846  12.970618  42.725653\n",
              "847  13.852317  43.758631\n",
              "848  13.144035  44.761750\n",
              "\n",
              "[849 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aFRMDnxG3yZ",
        "colab_type": "text"
      },
      "source": [
        "# **2. Variable modification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em1GhMP586_j",
        "colab_type": "text"
      },
      "source": [
        "**2.1. Establish equal number of repetitions per word**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLze9It2KrBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "87b64ea6-37df-4604-f42e-ec763f29d70c"
      },
      "source": [
        "# Ensure all words have same number of repetitions\n",
        "numreps=2     # Number of repetitions per word\n",
        "num_trials=10  # Number of runs of cross validation\n",
        "\n",
        "for i in range(len(reps)-1,-1,-1):\n",
        "  tl=sd.iloc[repsum[i]:repsum[i+1]]\n",
        "  u=repsum[i+1]-1\n",
        "  if reps[i]<numreps:\n",
        "    for r in range(len(matrix)-1,-1,-1):\n",
        "      if int(matrix.iloc[r]['Word'])==i:\n",
        "        matrix=matrix.drop(r)\n",
        "  elif reps[i]>numreps:\n",
        "    while reps[i]>numreps:\n",
        "      if tl[u]==tl.max():\n",
        "        tl[u]=0\n",
        "        matrix=matrix.drop(u)\n",
        "        reps[i]=reps[i]-1\n",
        "        u=repsum[i+1]-1\n",
        "      else:\n",
        "        u-=1\n",
        "\n",
        "print(matrix)\n",
        "print('Repetitions per word:',reps)\n",
        "exec(\"matrix.to_csv(path_or_buf='/content/matrix_'+str(numreps)+'.csv')\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Word  EMG0L  EMG0L  EMG0L  EMG0L  ...   OYR   OYR   OYR   OYR   OYR\n",
            "13    0.0    0.0    0.0    3.0   10.0  ...  74.0  74.0  74.0  74.0  74.0\n",
            "14    0.0    0.0    0.0   -8.0   -1.0  ...  75.0  74.0  75.0  75.0  75.0\n",
            "31    1.0    0.0    0.0   10.0   13.0  ...  92.0  91.0  89.0  86.0  82.0\n",
            "36    1.0    0.0    0.0   -2.0   -2.0  ...  31.0  31.0  31.0  31.0  31.0\n",
            "47    2.0    0.0    0.0   -3.0   -1.0  ...  39.0  41.0  44.0  44.0  44.0\n",
            "..    ...    ...    ...    ...    ...  ...   ...   ...   ...   ...   ...\n",
            "786  33.0    0.0    0.0    5.0  -12.0  ...  86.0  86.0  85.0  85.0  85.0\n",
            "808  34.0    0.0    0.0    0.0    2.0  ...  81.0  82.0  82.0  82.0  82.0\n",
            "810  34.0    0.0    0.0   -2.0   -1.0  ...  84.0  84.0  84.0  84.0  84.0\n",
            "835  35.0    0.0    0.0   23.0    1.0  ...  68.0  66.0  65.0  63.0  63.0\n",
            "836  35.0    0.0    0.0   -4.0   -8.0  ...  62.0  62.0  62.0  62.0  62.0\n",
            "\n",
            "[72 rows x 1701 columns]\n",
            "Repetitions per word: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv_VaSCnHJYz",
        "colab_type": "text"
      },
      "source": [
        "**2.2. Create sensor combinatory matrices: unaltered, normalized, and standardized**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7Ib41KW5f32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eliminate unnecessary columns to create combinatory matrices\n",
        "for v in products:\n",
        "  m=matrix.copy()\n",
        "  if v%3!=0:\n",
        "    m=m.drop(emg,1)\n",
        "  if v%5!=0:\n",
        "    m=m.drop(acc,1)\n",
        "  if v%7!=0:\n",
        "    m=m.drop(gyro,1)\n",
        "  if v%11!=0:\n",
        "    m=m.drop(ori,1)\n",
        "  \n",
        "  # Separate features from target values\n",
        "  x = m.iloc[:, m.columns!='Word']   # Features\n",
        "\n",
        "  # Create column of words instead of number\n",
        "  wordcol=np.empty(len(m), dtype=object)\n",
        "  z=0\n",
        "  wcol=[int(i) for i in m['Word'].values]\n",
        "  for f in wcol:\n",
        "    wordcol[z]=words[f]\n",
        "    z+=1\n",
        "  wordcol=np.asmatrix(wordcol)\n",
        "  regular=np.concatenate((np.transpose(wordcol),np.copy(m.iloc[:,1:])),axis=1)\n",
        "  products[n]=pd.DataFrame(regular,columns=m.columns).dropna(axis=1)\n",
        " \n",
        "  ## Normalize features so that each column is between 0 and 1\n",
        "  norm_matrix=(m-m.min())/(m.max()-m.min())\n",
        "  norm_matrix=np.concatenate((np.transpose(wordcol),norm_matrix.iloc[:,1:]),axis=1)\n",
        "  norm_matrix=pd.DataFrame(norm_matrix,columns=m.columns).dropna(axis=1)\n",
        "  norm.append(norm_matrix)\n",
        "  \n",
        "  ## Standardize features with mean=0 and deviation=1\n",
        "  standardized_matrix=StandardScaler().fit_transform(x)\n",
        "  standardized_matrix=np.concatenate((np.transpose(wordcol),standardized_matrix),axis=1)\n",
        "  standardized_matrix=pd.DataFrame(standardized_matrix,columns=m.columns).dropna(axis=1)\n",
        "  stand.append(standardized_matrix)\n",
        "  n+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJtV04hjOid6",
        "colab_type": "text"
      },
      "source": [
        "# **3. Definition of functions for steps**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQF9gp3gVloy",
        "colab_type": "text"
      },
      "source": [
        "**3.1. Split data into train and test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfHNiVxNVvK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def datasplit(inmatrix_p):\n",
        "    x = inmatrix_p.iloc[:, inmatrix_p.columns!='Word']   # Features\n",
        "    y = inmatrix_p.loc[:,'Word']     # Target\n",
        "    x_train_p, x_test_p, y_train_p, y_test_p = train_test_split(x, y, test_size=0.3)\n",
        "    return x_train_p, x_test_p, y_train_p, y_test_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGLs1pC8Vg15",
        "colab_type": "text"
      },
      "source": [
        "**3.2. Butterworth**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJjGC_1Q5r03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def butterworth(inmatrix_b):\n",
        "  high = 1/(50/2)\n",
        "  low = 23/(50/2)\n",
        "\n",
        "  b, a = sp.signal.butter(7, [high,low], btype='bandpass')\n",
        "\n",
        "  for r in emg:\n",
        "    if r in inmatrix_b:\n",
        "      # process EMG signal: filter EMG\n",
        "      emg_filtered = sp.signal.lfilter(b, a, inmatrix_b[[r]])\n",
        "      inmatrix_b[[r]]=emg_filtered\n",
        "  return inmatrix_b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxsIrFj9V7SX",
        "colab_type": "text"
      },
      "source": [
        "**3.3. PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7WTmphBWFnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pca(x_train_c, x_test_c, y_train_c, y_test_c):\n",
        "  pca = PCA(n_components=min(len(x_train_c), len(y_train_c)))\n",
        "  pca.fit(x_train_c)\n",
        "  x_t_train_pca = pca.transform(x_train_c)\n",
        "  x_t_test_pca = pca.transform(x_test_c)\n",
        "\n",
        "  # Plot\n",
        "  #print(\"Normalized matrix\")\n",
        "  #print(pca.explained_variance_ratio_)\n",
        "  #print(pca.singular_values_)\n",
        "  #plt.figure()\n",
        "  #plt.bar(fn[:100], pca.explained_variance_ratio_)\n",
        "  #plt.show()\n",
        "  #plt.bar(fn[:100], pca.singular_values_)\n",
        "  #plt.show()\n",
        "  return x_train_c, x_test_c, y_train_c, y_test_c, x_t_train_pca, x_t_test_pca"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrXL60g9WO_M",
        "colab_type": "text"
      },
      "source": [
        "**3.4. SVM with Grid Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz0otyHbWRRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def svm(x_train_s, x_test_s, y_train_s, y_test_s, x_t_train_s, x_t_test_s,combo):\n",
        "    parameters = {'kernel':('linear', 'poly', 'rbf', 'sigmoid'), 'C':[0.1, 1, 10, 100, 1000]}\n",
        "    svc = SVC(max_iter=1000)\n",
        "    #if int(numreps*0.3)<2:\n",
        "    #  nsplit=2\n",
        "    #else:\n",
        "    #  nsplit=int(numreps*0.3)\n",
        "    nested_scores=np.zeros(num_trials)\n",
        "    for t in range(num_trials):\n",
        "      inner_cv=KFold(n_splits=10,shuffle=True,random_state=i)\n",
        "      outer_cv=KFold(n_splits=10,shuffle=True,random_state=i)\n",
        "      #clf=GridSearchCV(svc,parameters,scoring='accuracy',n_jobs=1,cv=min(nsplit,10))\n",
        "      clf=GridSearchCV(svc,parameters,scoring='accuracy',n_jobs=1,cv=outer_cv)\n",
        "      clf.fit(x_t_train_s, y_train_s)\n",
        "      nested_scores=cross_val_score(clf,x_t_test_s,y_test_s,cv=outer_cv)\n",
        "      nested_scores[i]=nested_scores.mean()\n",
        "    #print('score', clf.score(x_t_test_s, y_test_s))\n",
        "    y_pred=clf.predict(x_t_test_s)\n",
        "    #print('pred label', y_pred)\n",
        "    #print('length',len(clf.predict(x_t_test_s)))\n",
        "\n",
        "    # Confusion matrix\n",
        "    #plot_confusion_matrix(clf, x_t_test_s, y_test_s,cmap=plt.cm.Blues)\n",
        "    #plt.title(combo)\n",
        "    #plt.figure(figsize=(50,50))\n",
        "    #plt.show()\n",
        "    bestpar=clf.best_params_\n",
        "    accuracy=nested_scores.mean()\n",
        "    svmresult=classification_report(y_test_s, y_pred)\n",
        "    return svmresult,accuracy, bestpar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIoQ54eagg4r",
        "colab_type": "text"
      },
      "source": [
        "# **4. Main code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKoS0bOpWV7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19212cad-923b-4c89-fdac-c6a9f66e21ad"
      },
      "source": [
        "for st in steps:\n",
        "  rownum+=1\n",
        "  columnnum=-1\n",
        "  for pr in products:\n",
        "    columnnum+=1\n",
        "    combo=nsteps[rownum]+' - '+comb[columnnum]\n",
        "    words=set(pr['Word']) # Obtain the target names for the SVM\n",
        "    # First step: set input matrix as regular, normalized or standardized\n",
        "    input_matrix=pr\n",
        "    if st%3==0: # Normalization\n",
        "      input_matrix=norm[columnnum]\n",
        "    if st%5==0: # Standardization\n",
        "      input_matrix=stand[columnnum]\n",
        "    # Second step: apply Butterworth\n",
        "    two_matrix=input_matrix\n",
        "    if st%7==0: # Butterworth\n",
        "      two_matrix=butterworth(input_matrix)\n",
        "    # Third step: split data for later steps\n",
        "    x_train, x_test, y_train, y_test=datasplit(two_matrix)\n",
        "    # Fourth step: apply PCA\n",
        "    x_t_train=x_train\n",
        "    x_t_test=x_test\n",
        "    if st%11==0: # PCA\n",
        "      x_train, x_test, y_train, y_test, x_t_train, x_t_test=pca(x_train, x_test, y_train, y_test)\n",
        "    # Fifth step: apply SVM\n",
        "    if st%13==0: # SVM\n",
        "      svmresults,accuracy,par=svm(x_train, x_test, y_train, y_test, x_t_train, x_t_test,combo)\n",
        "    print('The best parameters for',combo,'are:',par)\n",
        "    fresults[rownum,columnnum]=accuracy*100\n",
        "fresults=pd.DataFrame(fresults,index=nsteps,columns=comb)\n",
        "exec(\"fresults.to_csv(path_or_buf='/content/results_'+str(numreps)+'.csv')\")\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "execution_time = stop - start"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best parameters for V - E are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for V - A are: {'C': 100, 'kernel': 'sigmoid'}\n",
            "The best parameters for V - G are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for V - O are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for V - EA are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for V - EG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for V - EO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for V - AG are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for V - AO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for V - GO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for V - EAG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for V - EAO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for V - EGO are: {'C': 100, 'kernel': 'sigmoid'}\n",
            "The best parameters for V - AGO are: {'C': 100, 'kernel': 'sigmoid'}\n",
            "The best parameters for V - EAGO are: {'C': 100, 'kernel': 'sigmoid'}\n",
            "The best parameters for NV - E are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for NV - A are: {'C': 0.1, 'kernel': 'poly'}\n",
            "The best parameters for NV - G are: {'C': 0.1, 'kernel': 'poly'}\n",
            "The best parameters for NV - O are: {'C': 0.1, 'kernel': 'poly'}\n",
            "The best parameters for NV - EA are: {'C': 0.1, 'kernel': 'poly'}\n",
            "The best parameters for NV - EG are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for NV - EO are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NV - AG are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NV - AO are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NV - GO are: {'C': 0.1, 'kernel': 'poly'}\n",
            "The best parameters for NV - EAG are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for NV - EAO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for NV - EGO are: {'C': 0.1, 'kernel': 'poly'}\n",
            "The best parameters for NV - AGO are: {'C': 0.1, 'kernel': 'poly'}\n",
            "The best parameters for NV - EAGO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SV - E are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SV - A are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SV - G are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SV - O are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SV - EA are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SV - EG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SV - EO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SV - AG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SV - AO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SV - GO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SV - EAG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SV - EAO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SV - EGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SV - AGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SV - EAGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for BV - E are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BV - A are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for BV - G are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BV - O are: {'C': 0.1, 'kernel': 'poly'}\n",
            "The best parameters for BV - EA are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BV - EG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for BV - EO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BV - AG are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BV - AO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BV - GO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BV - EAG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for BV - EAO are: {'C': 10, 'kernel': 'poly'}\n",
            "The best parameters for BV - EGO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BV - AGO are: {'C': 100, 'kernel': 'sigmoid'}\n",
            "The best parameters for BV - EAGO are: {'C': 100, 'kernel': 'sigmoid'}\n",
            "The best parameters for PV - E are: {'C': 100, 'kernel': 'poly'}\n",
            "The best parameters for PV - A are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for PV - G are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for PV - O are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for PV - EA are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for PV - EG are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for PV - EO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for PV - AG are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for PV - AO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for PV - GO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for PV - EAG are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for PV - EAO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for PV - EGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for PV - AGO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for PV - EAGO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for NBV - E are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for NBV - A are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NBV - G are: {'C': 0.1, 'kernel': 'poly'}\n",
            "The best parameters for NBV - O are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NBV - EA are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for NBV - EG are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NBV - EO are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NBV - AG are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NBV - AO are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NBV - GO are: {'C': 0.1, 'kernel': 'poly'}\n",
            "The best parameters for NBV - EAG are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for NBV - EAO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for NBV - EGO are: {'C': 100, 'kernel': 'sigmoid'}\n",
            "The best parameters for NBV - AGO are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NBV - EAGO are: {'C': 100, 'kernel': 'sigmoid'}\n",
            "The best parameters for NPV - E are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NPV - A are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NPV - G are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NPV - O are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NPV - EA are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NPV - EG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NPV - EO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NPV - AG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NPV - AO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NPV - GO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NPV - EAG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NPV - EAO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NPV - EGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NPV - AGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NPV - EAGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBV - E are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SBV - A are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBV - G are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBV - O are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SBV - EA are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBV - EG are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SBV - EO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBV - AG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBV - AO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBV - GO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBV - EAG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBV - EAO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBV - EGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBV - AGO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SBV - EAGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SPV - E are: {'C': 100, 'kernel': 'poly'}\n",
            "The best parameters for SPV - A are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SPV - G are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SPV - O are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SPV - EA are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SPV - EG are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SPV - EO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SPV - AG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SPV - AO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SPV - GO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SPV - EAG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SPV - EAO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SPV - EGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SPV - AGO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SPV - EAGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for BPV - E are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BPV - A are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for BPV - G are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for BPV - O are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BPV - EA are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BPV - EG are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BPV - EO are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BPV - AG are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BPV - AO are: {'C': 100, 'kernel': 'sigmoid'}\n",
            "The best parameters for BPV - GO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for BPV - EAG are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for BPV - EAO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for BPV - EGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for BPV - AGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for BPV - EAGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NBPV - E are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NBPV - A are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NBPV - G are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NBPV - O are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NBPV - EA are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NBPV - EG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NBPV - EO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NBPV - AG are: {'C': 1, 'kernel': 'linear'}\n",
            "The best parameters for NBPV - AO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NBPV - GO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NBPV - EAG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NBPV - EAO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NBPV - EGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NBPV - AGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for NBPV - EAGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBPV - E are: {'C': 100, 'kernel': 'poly'}\n",
            "The best parameters for SBPV - A are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SBPV - G are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SBPV - O are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SBPV - EA are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBPV - EG are: {'C': 0.1, 'kernel': 'linear'}\n",
            "The best parameters for SBPV - EO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBPV - AG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBPV - AO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBPV - GO are: {'C': 10, 'kernel': 'rbf'}\n",
            "The best parameters for SBPV - EAG are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBPV - EAO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBPV - EGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBPV - AGO are: {'C': 10, 'kernel': 'sigmoid'}\n",
            "The best parameters for SBPV - EAGO are: {'C': 10, 'kernel': 'sigmoid'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PwH5XRYrIqd",
        "colab_type": "text"
      },
      "source": [
        "# **5. Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqoHNGBxrMHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "850b9f7e-4a1c-405b-df13-246f9c07c502"
      },
      "source": [
        "print(fresults)\n",
        "print('The maximum accuracy for',numreps,'repetitions is',fresults.max().max())\n",
        "print(\"The program executed in \"+str(execution_time))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             E          A          G  ...        EGO        AGO       EAGO\n",
            "V     5.500000  37.333333   9.166667  ...  11.000000  11.000000  25.666667\n",
            "NV    0.000000   0.000000   9.166667  ...  11.000000   5.500000  15.000000\n",
            "SV    0.000000   5.833333   0.000000  ...   0.000000  20.166667   4.000000\n",
            "BV    0.000000  20.166667  14.666667  ...  11.000000   5.500000   9.166667\n",
            "PV    0.000000  16.833333   0.000000  ...  44.666667  27.833333  16.500000\n",
            "NBV   0.000000  11.000000   0.000000  ...   5.500000  16.833333   0.000000\n",
            "NPV   0.000000   0.000000   0.000000  ...  16.833333  26.000000  25.666667\n",
            "SBV   5.500000  27.500000   0.000000  ...  11.000000  16.833333   3.666667\n",
            "SPV   0.000000  11.000000  20.166667  ...   0.000000  16.500000  27.833333\n",
            "BPV   0.333333   0.000000  16.833333  ...  16.500000  14.666667  22.666667\n",
            "NBPV  0.000000  31.166667   0.000000  ...   5.500000  16.833333  27.833333\n",
            "SBPV  0.000000   5.833333   0.333333  ...  20.500000  16.500000   5.833333\n",
            "\n",
            "[12 rows x 15 columns]\n",
            "The maximum accuracy for 2 repetitions is 48.0\n",
            "The program executed in 21750.653100137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK_pmaOQrYOu",
        "colab_type": "text"
      },
      "source": [
        "# **To-do list**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h57zKLByfy2Y",
        "colab_type": "text"
      },
      "source": [
        "-check what happens when combining diff data sources\n",
        "\n",
        "-graph components\n",
        "\n",
        "-find correlations\n",
        "\n",
        "-interpret pca results\n",
        "\n",
        "-try pca per individual/word\n",
        "\n",
        "-read dataset papers\n",
        "\n",
        "correlation component with word\n",
        "\n",
        "-try straight to svm\n",
        "\n",
        "-resend email\n",
        "\n",
        "-check what is the data\n",
        "\n",
        "-merge timeseries word index\n",
        "\n",
        "-see how stable each feature are\n",
        "\n",
        "-standard deviation timeseries\n",
        "\n",
        "-try without filter\n",
        "\n",
        "-multi-class classifier SVM\n",
        "\n",
        "**\n",
        "-try with 2 words, only emg\n",
        "-average per column\n",
        "-test each step\n",
        "-test svm with 2 matrices\n",
        "see if svm has access to test set \n",
        "maybe shifted per set \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyBtMxHArsn5",
        "colab_type": "text"
      },
      "source": [
        "# **Additional papers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScbnguG8ONoC",
        "colab_type": "text"
      },
      "source": [
        "https://www.researchgate.net/publication/303707429_Combining_Smartphone_and_Smartwatch_Sensor_Data_in_Activity_Recognition_Approaches_an_Experimental_Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHEMg2vvri2J",
        "colab_type": "text"
      },
      "source": [
        "# **References**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay3NExQ59xrM",
        "colab_type": "text"
      },
      "source": [
        "Different parameters of SVC https://medium.com/all-things-ai/in-depth-parameter-tuning-for-svc-758215394769\n",
        "\n",
        "https://stackoverflow.com/questions/56449262/how-to-upload-folders-to-google-colab\n",
        "\n",
        "https://github.com/datarail/datarail/issues/39\n",
        "\n",
        "https://dbader.org/blog/python-check-if-file-exists\n",
        "\n",
        "https://datacarpentry.org/python-socialsci/11-joins/index.html\n",
        "\n",
        "https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
        "\n",
        "https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
        "\n",
        "https://www.tutorialspoint.com/matplotlib/matplotlib_bar_plot.htm\n",
        "\n",
        "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.signal.butter.html\n",
        "\n",
        "https://stackoverflow.com/questions/32194967/how-to-do-pca-and-svm-for-classification-in-python\n",
        "\n",
        "https://stackoverflow.com/questions/6822725/rolling-or-sliding-window-iterator\n",
        "\n",
        "https://scikit-learn.org/stable/modules/cross_validation.html\n",
        "\n",
        "https://stackoverflow.com/questions/47684606/merge-cells-with-pandas\n",
        "\n",
        "https://scientificallysound.org/2016/08/18/python-analysing-emg-signals-part-3/\n",
        "\n",
        "https://stackoverflow.com/questions/58374492/python-valueerror-the-length-of-the-input-vector-x-must-be-greater-than-padle\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html\n",
        "\n",
        "https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "https://statinfer.com/204-4-2-calculating-sensitivity-and-specificity-in-python/\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/pandas-multi-index\n",
        "\n",
        "https://www.geeksforgeeks.org/how-to-get-rows-index-names-in-pandas-dataframe/\n",
        "\n",
        "https://stackoverflow.com/questions/28140771/select-only-one-index-of-multiindex-dataframe\n",
        "\n",
        "https://www.educative.io/edpresso/how-to-create-a-confusion-matrix-in-python-using-scikit-learn\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
        "\n",
        "http://www.datasciencemadesimple.com/standard-deviation-function-python-pandas-row-column/\n",
        "\n",
        "https://stackoverflow.com/questions/39047915/concat-series-onto-dataframe-with-column-name\n",
        "\n",
        "https://www.programiz.com/python-programming/methods/list/index\n",
        "\n",
        "https://stackoverflow.com/questions/14463277/how-to-disable-python-warnings\n",
        "\n",
        "https://www.phusewiki.org/wiki/index.php?title=Program_Header\n",
        "\n",
        "https://github.com/scikit-learn-contrib/skope-rules/issues/18\n",
        "\n",
        "https://github.com/scikit-learn/scikit-learn/issues/13176\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "\n",
        "https://github.com/scikit-learn/scikit-learn/issues/11020\n",
        "\n",
        "https://stackoverflow.com/questions/1557571/how-do-i-get-time-of-a-python-programs-execution\n",
        "\n",
        "https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "\n",
        "Transfer project from GitHub to GitLab https://docs.gitlab.com/ee/user/project/import/github.html\n"
      ]
    }
  ]
}