{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Horizontal2MyoASL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN74FfeWFwCB0weeIFw3HNu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michelleaeh/Dissertation/blob/master/Horizontal2MyoASL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH79ogCWrzbt",
        "colab_type": "text"
      },
      "source": [
        "**Myo armband dataset from https://data.mendeley.com/datasets/wgswcr8z24/2**\n",
        "\n",
        "\n",
        "**The dataset consits of .csv files collected from two Myo armbands. The format of the files are [word_name]_[id]. The ‘word_name’ is the English translation of the American Sign Language word used and the ‘id’ is a unique identifier. The .zip for each of the above links has sub-folders for each User.**\n",
        "\n",
        "**Each file has 50 columns. They represent a sub-sampled data collection from two Myo devices worn on left and right hands of the signer. The first column is the ‘Counter’ that goes from 1 to 50.**\n",
        "\n",
        "**The following columns are of the format: [Sensor][pod/direction][left/right]. For instance the EMG reading for the first EMG pod (out of 8) on the left hand would be called EMG0R and the accelerometer reading for the Z axis on the left hand would be called: AXL**\n",
        "\n",
        "**If you use this dataset please cite the following papers:**\n",
        "\n",
        "**@inproceedings{paudyal2016sceptre,\n",
        "title={Sceptre: a pervasive, non-invasive, and programmable gesture recognition technology},\n",
        "author={Paudyal, Prajwal and Banerjee, Ayan and Gupta, Sandeep KS},\n",
        "booktitle={Proceedings of the 21st International Conference on Intelligent User Interfaces},\n",
        "pages={282--293},\n",
        "year={2016},\n",
        "organization={ACM}\n",
        "}**\n",
        "\n",
        "**@inproceedings{paudyal2017dyfav,\n",
        "title={Dyfav: Dynamic feature selection and voting for real-time recognition of fingerspelled alphabet using wearables},\n",
        "author={Paudyal, Prajwal and Lee, Junghyo and Banerjee, Ayan and Gupta, Sandeep KS},\n",
        "booktitle={Proceedings of the 22nd International Conference on Intelligent User Interfaces},\n",
        "pages={457--467},\n",
        "year={2017},\n",
        "organization={ACM}\n",
        "}**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHNKWJHfhpMy",
        "colab_type": "text"
      },
      "source": [
        "**Frequency:**\n",
        "\n",
        "50Hz sampling rate\n",
        "\n",
        "**Words:**\n",
        "\n",
        "*36 total words*\n",
        "\n",
        "allmorning, bird, blue, cantsleep, cat, colrunnynose, continuouslyforanhour, cost, day, dollar, everymorning, everynight, gold, goodnight, happy, headache, home, horse, hot, hurt, itching, large, mom, monthly, notfeelgood, orange, pizza, please, shirt, soreness, swelling, takeliquidmedicine, thatsterrible, tired, upsetstomach, wash\n",
        "\n",
        "\n",
        "**Filenames:**\n",
        "\n",
        "*849 total files*\n",
        "\n",
        "(word)_(user#)(try#)\n",
        "\n",
        "\n",
        "**Columns of files:**\n",
        "\n",
        "Counter  (1 -> 50)\n",
        "\n",
        "EMG0L -> EMG7L  (EMG sensor readings)\n",
        "\n",
        "AXL, AYL, AZL  (accelerometer readings)\n",
        "\n",
        "GXL, GYL, GZL  (gyroscope readings)\n",
        "\n",
        "ORL, OPL, OYL  (magnetometer readings?)\n",
        "\n",
        "EMG0R -> EMG7R  (EMG sensor readings)\n",
        "\n",
        "AXR, AYR, AZR  (accelerometer readings)\n",
        "\n",
        "GXR, GYR, GZR  (gyroscope readings)\n",
        "\n",
        "ORR, OPR, OYR  (magnetometer readings?)\n",
        "\n",
        "features=['EMG0L', 'EMG1L', 'EMG2L', 'EMG3L', 'EMG4L', 'EMG5L', 'EMG6L', 'EMG7L', 'AXL', 'AYL', 'AZL', 'GXL', 'GYL', 'GZL', 'ORL', 'OPL', 'OYL', 'EMG0R', 'EMG1R', 'EMG2R', 'EMG3R', 'EMG4R', 'EMG5R', 'EMG6R', 'EMG7R', 'AXR', 'AYR', 'AZR', 'GXR', 'GYR', 'GZR', 'ORR', 'OPR', 'OYR']\n",
        "\n",
        "\n",
        "**Size of files:**\n",
        "\n",
        "All files are 50 rows x 35 columns except continuouslyforanhour_22.csv, headache_52.csv, home_61.csv, and mom_82.csv which are 101 rows x 35 columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVqdAdxkr-U5",
        "colab_type": "text"
      },
      "source": [
        "**Steps:**\n",
        "\n",
        "1. Combine files\n",
        "2. Normalize or standardize matrix\n",
        "3. Apply Butterworth\n",
        "4. Apply PCA\n",
        "5. Input to SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TnTycFtrpHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import warnings\n",
        "\n",
        "from google.colab import files\n",
        "from mpl_toolkits import mplot3d\n",
        "from scipy import signal\n",
        "from scipy.io import loadmat\n",
        "from sklearn import metrics\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Import zip containing all files\n",
        "file_name = \"/content/2MyoASL.zip\"\n",
        "\n",
        "# Extract all files from zip\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHsqsj2NRpEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate matrices for all combinations of sensors (E=3, A=5, G=7, O=11)\n",
        "products=[3, 5, 7, 11, 15, 21, 33, 35, 55, 77, 105, 165, 231, 385, 1155]\n",
        "comb=['e', 'a', 'g', 'o', 'ea', 'eg', 'eo', 'ag', 'ao', 'go', 'eag', 'eao', 'ego', 'ago', 'eago']\n",
        "emg=['EMG0L', 'EMG1L', 'EMG2L', 'EMG3L', 'EMG4L', 'EMG5L', 'EMG6L', 'EMG7L', \n",
        "    'EMG0R', 'EMG1R', 'EMG2R', 'EMG3R', 'EMG4R', 'EMG5R', 'EMG6R', 'EMG7R']\n",
        "acc=['AXL', 'AYL', 'AZL', 'AXR', 'AYR', 'AZR']\n",
        "gyro=['GXL', 'GYL', 'GZL', 'GXR', 'GYR', 'GZR']\n",
        "ori=['ORL', 'OPL', 'OYL', 'ORR', 'OPR', 'OYR']\n",
        "\n",
        "# Initialization of counters\n",
        "words=['allmorning', 'bird', 'blue', 'cantsleep', 'cat', 'coldrunnynose', 'continuouslyforanhour', 'cost', 'day', \n",
        "       'dollar', 'everymorning', 'everynight', 'gold', 'goodnight', 'happy', 'headache', 'home', 'horse', 'hot', \n",
        "       'hurt', 'itching', 'large', 'mom', 'monthly', 'notfeelgood', 'orange', 'pizza', 'please', 'shirt', \n",
        "       'soreness', 'swelling', 'takeliquidmedicine', 'thatsterrible', 'tired', 'upsetstomach', 'wash']\n",
        "lengths=np.zeros(849, dtype=int)\n",
        "reps=np.zeros(36,dtype=int)\n",
        "features=np.zeros(15)\n",
        "target=np.zeros(15)\n",
        "matrix=np.zeros(1)\n",
        "\n",
        "fn=np.arange(35)\n",
        "wordnum=-1\n",
        "counter=-1\n",
        "n=0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQFtofv7yG7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "e39b290e-f537-4390-c096-84bf602076f3"
      },
      "source": [
        "# Combine all files\n",
        "for w in words:\n",
        "  repcount=0\n",
        "  wordnum+=1\n",
        "\n",
        "  for i in range (10, 120):\n",
        "    path='/content/2MyoASL/' + w + '_' + str(i) + '.csv'\n",
        "\n",
        "    if os.path.exists(path)==True:\n",
        "      counter+=1\n",
        "      repcount+=1\n",
        "      trial=pd.read_csv(path)\n",
        "      #lengths[counter-1]=len(trial)\n",
        "\n",
        "      trial.reset_index(drop=True)\n",
        "      #print(trial)\n",
        "      \n",
        "      # Assign word number to one row\n",
        "      row=np.zeros(1)\n",
        "      for t in range(35):\n",
        "        if t==0:\n",
        "          row[0]=wordnum\n",
        "        else:\n",
        "          sensor=trial.iloc[0:50,t].values\n",
        "          sensor.reshape([1,50])\n",
        "          row=np.concatenate((row, sensor))\n",
        "      #print(row)\n",
        "      #print('length',len(row))\n",
        "      #print(row[3])\n",
        "      prev=row\n",
        "      \n",
        "      # Combine all trials\n",
        "      if counter==0:\n",
        "        matrix=prev\n",
        "      else:\n",
        "        matrix=np.concatenate([matrix,prev])\n",
        "      #print(matrix)\n",
        "      #print(\"length\",len(matrix))\n",
        "#matrix=np.delete(matrix, [0])\n",
        "matrix=matrix.reshape([849,1701])\n",
        "\n",
        "matrix=pd.DataFrame(matrix)\n",
        "print(matrix)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     0     1     2     3     4     ...   1696   1697   1698   1699   1700\n",
            "0     0.0   0.0   0.0  -3.0  -1.0  ...   83.0   83.0   83.0   83.0   83.0\n",
            "1     0.0   0.0   0.0   4.0  -2.0  ...   83.0   83.0   83.0   83.0   83.0\n",
            "2     0.0   0.0   0.0  -8.0  -1.0  ...   84.0   84.0   84.0   84.0   84.0\n",
            "3     0.0   0.0   0.0  -1.0 -19.0  ...   83.0   83.0   83.0   83.0   83.0\n",
            "4     0.0   0.0   0.0   1.0 -16.0  ...   93.0   91.0   91.0   91.0   91.0\n",
            "..    ...   ...   ...   ...   ...  ...    ...    ...    ...    ...    ...\n",
            "844  35.0   0.0   0.0  -2.0   0.0  ...  106.0  104.0  100.0   98.0   95.0\n",
            "845  35.0   0.0   0.0   2.0  -8.0  ...  176.0  176.0  177.0  177.0  177.0\n",
            "846  35.0   0.0   0.0  -8.0  26.0  ...  177.0  176.0  175.0  175.0  176.0\n",
            "847  35.0   0.0   0.0  -1.0  21.0  ...  178.0  178.0  179.0  179.0  179.0\n",
            "848  35.0   0.0   0.0   8.0 -19.0  ...  179.0  179.0  179.0  179.0    0.0\n",
            "\n",
            "[849 rows x 1701 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1NXKFmNWLB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Average and standard deviation of each sensor\n",
        "#avg=matrix.mean(axis=0)\n",
        "#sd=matrix.std(axis=0)\n",
        "#pd.concat([avg.rename('Mean'),sd.rename('St. dev.')], axis=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cry7YARuOhoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attempt=matrix"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7Ib41KW5f32",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "4d5c2d27-cb6d-4d30-83f1-d86b30768023"
      },
      "source": [
        "# Eliminate unnecessary columns to create combinatory matrices\n",
        "for v in products:\n",
        "  m=matrix\n",
        "  if v%3!=0:\n",
        "    m=m.drop(emg,1)\n",
        "  if v%5!=0:\n",
        "    m=m.drop(acc,1)\n",
        "  if v%7!=0:\n",
        "    m=m.drop(gyro,1)\n",
        "  if v%11!=0:\n",
        "    m=m.drop(ori,1)\n",
        "  products[n]=m\n",
        "  exec(comb[n]+\"=products[n]\")\n",
        "  n+=1\n",
        "  \n",
        "  # Normalize and Standardize each of the 15 matrices\n",
        "  # Separate features from target values\n",
        "  x = m.loc[:, m.columns].values   # Features\n",
        "  ######################y = m.loc[:,'Counter'].values               # Target\n",
        "  ####y = m.index[m['Word']]\n",
        "\n",
        "  #y=m.iloc[0]\n",
        "  #\"None of [Index(['Counter'], dtype='object')] are in the [columns]\"\n",
        "\n",
        "  ## Normalize features so that each column is between 0 and 1\n",
        "  norm_matrix=(m-m.min())/(m.max()-m.min())\n",
        "  exec(\"norm_matrix_\"+comb[n-1]+\"=pd.DataFrame(norm_matrix)\")\n",
        "\n",
        "  # Normalize features\n",
        "#  normalized_matrix=(x-x.min())/(x.max()-x.min())\n",
        "#  exec(\"normalized_matrix_\"+comb[n-1]+\"=pd.DataFrame(normalized_matrix)\")\n",
        "\n",
        "  # Standardize features with mean=0 and deviation=1\n",
        "  standardized_matrix=StandardScaler().fit_transform(x)\n",
        "  exec(\"standardized_matrix_\"+comb[n-1]+\"=pd.DataFrame(standardized_matrix)\")\n",
        "\n",
        "  # Save data frames as csv files\n",
        "  #matrix.to_csv(path_or_buf='/content/matrix_'+comb[n-1]+'.csv')\n",
        "  exec(\"norm_matrix_\"+comb[n-1]+\".to_csv(path_or_buf='/content/normmatrix_'+comb[n-1]+'.csv')\")\n",
        "#  exec(\"normalized_matrix_\"+comb[n-1]+\".to_csv(path_or_buf='/content/normalizedmatrix_'+comb[n-1]+'.csv')\")\n",
        "  exec(\"standardized_matrix_\"+comb[n-1]+\".to_csv(path_or_buf='/content/standardizedmatrix_'+comb[n-1]+'.csv')\")\n",
        "\n",
        "print(type(m))\n",
        "print(type(products))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9c2f849cfb92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgyro\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3995\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3996\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3997\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3998\u001b[0m         )\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3934\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3935\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3936\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3970\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5017\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5018\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5020\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['AXL' 'AYL' 'AZL' 'AXR' 'AYR' 'AZR'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IaWFWIUrT5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nmatrix=norm_matrix_eago"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJjGC_1Q5r03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Butterworth\n",
        "#high = 20/(1000/2)\n",
        "#low = 450/(1000/2)\n",
        "high = 1/(50/2)\n",
        "low = 23/(50/2)\n",
        "\n",
        "b, a = sp.signal.butter(4, [high,low], btype='bandpass')\n",
        "\n",
        "for r in emg:\n",
        "  norm_matrix_eago[[r]]\n",
        "  # process EMG signal: filter EMG\n",
        "  emg_filtered = sp.signal.lfilter(b, a, norm_matrix_eago[[r]])\n",
        "  norm_matrix_eago[[r]]=emg_filtered"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oegUzb00nsA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "buttermatrix=norm_matrix_eago"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufJX_eg5fmXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_top=norm_matrix_eago.head()\n",
        "#list(data_top.index.values)\n",
        "#####indices=list(norm_matrix_eago.index.values.tolist()) \n",
        "#indices=norm_matrix_eago.index.get_level_values('Word')\n",
        "#print(indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I16C6HCyrFZr",
        "colab_type": "text"
      },
      "source": [
        "**Combinations of steps for classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw8kyulNOsmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directly to SVM\n",
        "x = attempt.loc[:, attempt.columns].values   # Features\n",
        "#y = m.loc[:,['Counter']].values               # Target\n",
        "y=attempt.index.get_level_values('Word')     # Target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(x_train, y_train)\n",
        "print ('score', clf.score(x_test, y_test))\n",
        "y_pred=clf.predict(x_test)\n",
        "print ('pred label', y_pred)\n",
        "print('length',len(clf.predict(x_test)))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, x_test, y_test,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.figure(figsize=(50,50))\n",
        "plt.show()\n",
        "\n",
        "#metrics.classification_report(y_test,y_pred, target_names=words)\n",
        "print(classification_report(y_test, y_pred, target_names=words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgPwhYZvrn3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalized to SVM\n",
        "x = nmatrix.loc[:, nmatrix.columns].values   # Features\n",
        "#y = m.loc[:,['Counter']].values               # Target\n",
        "y=nmatrix.index.get_level_values('Word')              # Target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(x_train, y_train)\n",
        "print ('score', clf.score(x_test, y_test))\n",
        "y_pred=clf.predict(x_test)\n",
        "print ('pred label', y_pred)\n",
        "print('length',len(clf.predict(x_test)))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, x_test, y_test,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.figure(figsize=(50,50))\n",
        "plt.show()\n",
        "\n",
        "#metrics.classification_report(y_test,y_pred)\n",
        "print(classification_report(y_test, y_pred, target_names=words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OL74iKMnWZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalized, Butterworth to SVM\n",
        "x = buttermatrix.loc[:, buttermatrix.columns].values   # Features\n",
        "#y = m.loc[:,['Counter']].values               # Target\n",
        "y=buttermatrix.index.get_level_values('Word')              # Target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(x_train, y_train)\n",
        "print ('score', clf.score(x_test, y_test))\n",
        "y_pred=clf.predict(x_test)\n",
        "print ('pred label', y_pred)\n",
        "print('length',len(clf.predict(x_test)))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, x_test, y_test,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.figure(figsize=(50,50))\n",
        "plt.show()\n",
        "\n",
        "#metrics.classification_report(y_test,y_pred)\n",
        "print(classification_report(y_test, y_pred, target_names=words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riv-kFwa9oMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PCA for norm_matrix\n",
        "#norm_matrix_eago.reset_index(drop=True, inplace=True)\n",
        "#m.reset_index(drop=True, inplace=True)\n",
        "\n",
        "x = norm_matrix_eago.loc[:, norm_matrix_eago.columns].values   # Features\n",
        "#y = m.loc[:,['Counter']].values               # Target\n",
        "y=norm_matrix_eago.index.get_level_values('Word')              # Target\n",
        "print(y)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)\n",
        "\n",
        "pca = PCA(n_components=30)\n",
        "pca.fit(x_train)\n",
        "x_t_train = pca.transform(x_train)\n",
        "x_t_test = pca.transform(x_test)\n",
        "\n",
        "#### plot\n",
        "print(\"Normalized matrix\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn[:30],pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn[:30],pca.singular_values_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSevZSPDFZjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalized, Butterworth, PCA to SVM\n",
        "clf = SVC()\n",
        "clf.fit(x_t_train, y_train)\n",
        "print ('score', clf.score(x_t_test, y_test))\n",
        "y_pred=clf.predict(x_t_test)\n",
        "print ('pred label', y_pred)\n",
        "print('length',len(clf.predict(x_t_test)))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, x_t_test, y_test,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.figure(figsize=(50,50))\n",
        "plt.show()\n",
        "\n",
        "#metrics.classification_report(y_test,y_pred)\n",
        "print(classification_report(y_test, y_pred, target_names=words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h57zKLByfy2Y",
        "colab_type": "text"
      },
      "source": [
        "TODO:\n",
        "\n",
        "-check what happens when combining diff data sources\n",
        "\n",
        "-graph components\n",
        "\n",
        "find correlations\n",
        "\n",
        "-interpret pca results\n",
        "\n",
        "-try pca per individual/word\n",
        "\n",
        "-read dataset papers\n",
        "\n",
        "correlation component with word\n",
        "\n",
        "-try straight to svm\n",
        "\n",
        "-resend email\n",
        "\n",
        "check what is the data\n",
        "\n",
        "-merge timeseries word index\n",
        "\n",
        "see how stable each feature are\n",
        "\n",
        "standard deviation timeseries\n",
        "\n",
        "-try without filter\n",
        "\n",
        "multi-class classifier SVM\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScbnguG8ONoC",
        "colab_type": "text"
      },
      "source": [
        "https://www.researchgate.net/publication/303707429_Combining_Smartphone_and_Smartwatch_Sensor_Data_in_Activity_Recognition_Approaches_an_Experimental_Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay3NExQ59xrM",
        "colab_type": "text"
      },
      "source": [
        "References\n",
        "\n",
        "https://stackoverflow.com/questions/56449262/how-to-upload-folders-to-google-colab\n",
        "\n",
        "https://github.com/datarail/datarail/issues/39\n",
        "\n",
        "https://dbader.org/blog/python-check-if-file-exists\n",
        "\n",
        "https://datacarpentry.org/python-socialsci/11-joins/index.html\n",
        "\n",
        "https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
        "\n",
        "https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
        "\n",
        "https://www.tutorialspoint.com/matplotlib/matplotlib_bar_plot.htm\n",
        "\n",
        "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.signal.butter.html\n",
        "\n",
        "https://stackoverflow.com/questions/32194967/how-to-do-pca-and-svm-for-classification-in-python\n",
        "\n",
        "https://stackoverflow.com/questions/6822725/rolling-or-sliding-window-iterator\n",
        "\n",
        "https://scikit-learn.org/stable/modules/cross_validation.html\n",
        "\n",
        "https://stackoverflow.com/questions/47684606/merge-cells-with-pandas\n",
        "\n",
        "https://scientificallysound.org/2016/08/18/python-analysing-emg-signals-part-3/\n",
        "\n",
        "https://stackoverflow.com/questions/58374492/python-valueerror-the-length-of-the-input-vector-x-must-be-greater-than-padle\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html\n",
        "\n",
        "https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "https://statinfer.com/204-4-2-calculating-sensitivity-and-specificity-in-python/\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/pandas-multi-index\n",
        "\n",
        "https://www.geeksforgeeks.org/how-to-get-rows-index-names-in-pandas-dataframe/\n",
        "\n",
        "https://stackoverflow.com/questions/28140771/select-only-one-index-of-multiindex-dataframe\n",
        "\n",
        "https://www.educative.io/edpresso/how-to-create-a-confusion-matrix-in-python-using-scikit-learn\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
        "\n",
        "http://www.datasciencemadesimple.com/standard-deviation-function-python-pandas-row-column/\n",
        "\n",
        "https://stackoverflow.com/questions/39047915/concat-series-onto-dataframe-with-column-name\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V77MeC59AHdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "### Combine all files\n",
        "words=['allmorning', 'bird', 'blue', 'cantsleep', 'cat', 'coldrunnynose', 'continuouslyforanhour', 'cost', 'day', 'dollar', 'everymorning', 'everynight', 'gold', 'goodnight', 'happy', 'headache', 'home', 'horse', 'hot', 'hurt', 'itching', 'large', 'mom', 'monthly', 'notfeelgood', 'orange', 'pizza', 'please', 'shirt', 'soreness', 'swelling', 'takeliquidmedicine', 'thatsterrible', 'tired', 'upsetstomach', 'wash']\n",
        "lengths=np.zeros(849, dtype=int)\n",
        "reps=np.zeros(36,dtype=int)\n",
        "wordnum=-1\n",
        "counter=0\n",
        "\n",
        "for w in words:\n",
        "  repcount=0\n",
        "  wordnum+=1\n",
        "\n",
        "  for i in range (10, 120):\n",
        "    path='/content/2MyoASL/' + w + '_' + str(i) + '.csv'\n",
        "\n",
        "    if os.path.exists(path)==True:\n",
        "      counter+=1\n",
        "      repcount+=1\n",
        "      trial=pd.read_csv(path)\n",
        "      lengths[counter-1]=len(trial)\n",
        "      \n",
        "      # Replace counter with evaluated term\n",
        "      for r in range(0,len(trial)):\n",
        "        trial.iloc[r,0]=wordnum\n",
        "        \n",
        "      # Combine all trials\n",
        "      if path=='/content/2MyoASL/allmorning_10.csv':\n",
        "          matrix=trial\n",
        "          \n",
        "          # Create plot for EMG\n",
        "\n",
        "          # Create plot for accelerometer\n",
        "          plt.figure()\n",
        "          alx=plt.axes(projection='3d')\n",
        "          alx.plot3D(trial.loc[:, 'AXL'].values, trial.loc[:, 'AYL'].values, trial.loc[:, 'AZL'].values)\n",
        "          alx.set_title('Accelerometer on left arm')\n",
        "\n",
        "          plt.figure()\n",
        "          arx=plt.axes(projection='3d')\n",
        "          arx.plot3D(trial.loc[:, 'AXR'].values, trial.loc[:, 'AYR'].values, trial.loc[:, 'AZR'].values)\n",
        "          arx.set_title('Accelerometer on right arm')\n",
        "\n",
        "          # Create plot for gyroscope\n",
        "          plt.figure()\n",
        "          glx=plt.axes(projection='3d')\n",
        "          glx.plot3D(trial.loc[:, 'GXL'].values, trial.loc[:, 'GYL'].values, trial.loc[:, 'GZL'].values)\n",
        "          glx.set_title('Gyroscope on left arm')\n",
        "\n",
        "          plt.figure()\n",
        "          grx=plt.axes(projection='3d')\n",
        "          grx.plot3D(trial.loc[:, 'GXR'].values, trial.loc[:, 'GYR'].values, trial.loc[:, 'GZR'].values)\n",
        "          grx.set_title('Gyroscope on right arm')\n",
        "      else:\n",
        "          matrix=pd.concat([matrix, trial])\n",
        "\n",
        "          ###############################################\n",
        "          # Create plot for accelerometer\n",
        "          alx.plot3D(trial.loc[:, 'AXL'].values, trial.loc[:, 'AYL'].values, trial.loc[:, 'AZL'].values)\n",
        "          arx.plot3D(trial.loc[:, 'AXR'].values, trial.loc[:, 'AYR'].values, trial.loc[:, 'AZR'].values)\n",
        "          #plt.show()\n",
        "\n",
        "          # Create plot for gyroscope\n",
        "          glx.plot3D(trial.loc[:, 'GXL'].values, trial.loc[:, 'GYL'].values, trial.loc[:, 'GZL'].values)\n",
        "          grx.plot3D(trial.loc[:, 'GXR'].values, trial.loc[:, 'GYR'].values, trial.loc[:, 'GZR'].values)\n",
        "          ###############################################\n",
        "\n",
        "  reps[wordnum]=repcount\n",
        "plt.show()\n",
        "\"\"\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knhJG10SD22U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "# PCA for normmatrix\n",
        "pca = PCA(n_components=35)\n",
        "comp=pca.fit_transform(norm_matrix_eago)\n",
        "principal=pd.DataFrame(data=comp, columns=['PC 0', 'PC 1', 'PC 2', 'PC 3', 'PC 4', 'PC 5', 'PC 6', 'PC 7', 'PC 8', 'PC 9', 'PC 10', \n",
        "                                           'PC 11', 'PC 12', 'PC 13', 'PC 14', 'PC 16', 'PC 17', 'PC 18', 'PC 19', 'PC 20', \n",
        "                                           'PC 21', 'PC 22', 'PC 23', 'PC 24', 'PC 25', 'PC 26', 'PC 27', 'PC 28', 'PC 29', \n",
        "                                           'PC 30', 'PC 31', 'PC 32', 'PC 33', 'PC 34', 'PC35'])\n",
        "#principal.reset_index(drop=True, inplace=True)\n",
        "#norm_matrix_eago[['Counter']].reset_index(drop=True, inplace=True)\n",
        "norm_matrix_eago.reset_index(drop=True, inplace=True)\n",
        "m.reset_index(drop=True, inplace=True)\n",
        "#finaldf=pd.join([principal, norm_matrix_eago[['Counter']]], axis=1, ignore_index=True).reset_index()\n",
        "finaldf=principal.join(m[['Counter']],how='outer')\n",
        "finaldf=finaldf.drop(columns=['PC 0'])\n",
        "####finaldf=principal\n",
        "####print(m['Counter'])\n",
        "####finaldf['Word']=m['Counter']\n",
        "#finaldf=pd.concat([principal,norm_matrix_eago[['Counter']]], axis=1, ignore_index=True)\n",
        "\n",
        "print(\"Normalized matrix\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn,pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn,pca.singular_values_)\n",
        "plt.show()\n",
        "print(finaldf)\n",
        "#print(principal.join(norm_matrix_eago[['Counter']],how='inner'))\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "# PCA for normalizedmatrix\n",
        "pca = PCA(n_components=34)\n",
        "pca.fit(normalized_matrix)\n",
        "print(\"Normalized features\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn[0:34],pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn[0:34],pca.singular_values_)\n",
        "plt.show()\n",
        "\n",
        "# PCA for standardizedmatrix\n",
        "pca = PCA(n_components=34)\n",
        "pca.fit(standardized_matrix)\n",
        "print(\"Standardized features\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn[0:34],pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn[0:34],pca.singular_values_)\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}