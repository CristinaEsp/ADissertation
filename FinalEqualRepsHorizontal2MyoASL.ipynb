{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalEqualRepsHorizontal2MyoASL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8jLxiAwpHUrt"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNY3HRkE93CceAMcrz9GoRZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michelleaeh/Dissertation/blob/master/FinalEqualRepsHorizontal2MyoASL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jLxiAwpHUrt",
        "colab_type": "text"
      },
      "source": [
        "# **Data description**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH79ogCWrzbt",
        "colab_type": "text"
      },
      "source": [
        "**Myo armband dataset from https://data.mendeley.com/datasets/wgswcr8z24/2**\n",
        "\n",
        "\n",
        "**The dataset consits of .csv files collected from two Myo armbands. The format of the files are [word_name]_[id]. The ‘word_name’ is the English translation of the American Sign Language word used and the ‘id’ is a unique identifier. The .zip for each of the above links has sub-folders for each User.**\n",
        "\n",
        "**Each file has 50 columns. They represent a sub-sampled data collection from two Myo devices worn on left and right hands of the signer. The first column is the ‘Counter’ that goes from 1 to 50.**\n",
        "\n",
        "**The following columns are of the format: [Sensor][pod/direction][left/right]. For instance the EMG reading for the first EMG pod (out of 8) on the left hand would be called EMG0R and the accelerometer reading for the Z axis on the left hand would be called: AXL**\n",
        "\n",
        "**If you use this dataset please cite the following papers:**\n",
        "\n",
        "**@inproceedings{paudyal2016sceptre,\n",
        "title={Sceptre: a pervasive, non-invasive, and programmable gesture recognition technology},\n",
        "author={Paudyal, Prajwal and Banerjee, Ayan and Gupta, Sandeep KS},\n",
        "booktitle={Proceedings of the 21st International Conference on Intelligent User Interfaces},\n",
        "pages={282--293},\n",
        "year={2016},\n",
        "organization={ACM}\n",
        "}**\n",
        "\n",
        "**@inproceedings{paudyal2017dyfav,\n",
        "title={Dyfav: Dynamic feature selection and voting for real-time recognition of fingerspelled alphabet using wearables},\n",
        "author={Paudyal, Prajwal and Lee, Junghyo and Banerjee, Ayan and Gupta, Sandeep KS},\n",
        "booktitle={Proceedings of the 22nd International Conference on Intelligent User Interfaces},\n",
        "pages={457--467},\n",
        "year={2017},\n",
        "organization={ACM}\n",
        "}**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHNKWJHfhpMy",
        "colab_type": "text"
      },
      "source": [
        "**Frequency:**\n",
        "\n",
        "50Hz sampling rate\n",
        "\n",
        "**Words:**\n",
        "\n",
        "*36 total words*\n",
        "\n",
        "allmorning, bird, blue, cantsleep, cat, colrunnynose, continuouslyforanhour, cost, day, dollar, everymorning, everynight, gold, goodnight, happy, headache, home, horse, hot, hurt, itching, large, mom, monthly, notfeelgood, orange, pizza, please, shirt, soreness, swelling, takeliquidmedicine, thatsterrible, tired, upsetstomach, wash\n",
        "\n",
        "\n",
        "**Filenames:**\n",
        "\n",
        "*849 total files*\n",
        "\n",
        "(word)_(user#)(try#)\n",
        "\n",
        "\n",
        "**Columns of files:**\n",
        "\n",
        "Counter  (1 -> 50)\n",
        "\n",
        "EMG0L -> EMG7L  (EMG sensor readings)\n",
        "\n",
        "AXL, AYL, AZL  (accelerometer readings)\n",
        "\n",
        "GXL, GYL, GZL  (gyroscope readings)\n",
        "\n",
        "ORL, OPL, OYL  (magnetometer readings?)\n",
        "\n",
        "EMG0R -> EMG7R  (EMG sensor readings)\n",
        "\n",
        "AXR, AYR, AZR  (accelerometer readings)\n",
        "\n",
        "GXR, GYR, GZR  (gyroscope readings)\n",
        "\n",
        "ORR, OPR, OYR  (magnetometer readings?)\n",
        "\n",
        "features=['EMG0L', 'EMG1L', 'EMG2L', 'EMG3L', 'EMG4L', 'EMG5L', 'EMG6L', 'EMG7L', 'AXL', 'AYL', 'AZL', 'GXL', 'GYL', 'GZL', 'ORL', 'OPL', 'OYL', 'EMG0R', 'EMG1R', 'EMG2R', 'EMG3R', 'EMG4R', 'EMG5R', 'EMG6R', 'EMG7R', 'AXR', 'AYR', 'AZR', 'GXR', 'GYR', 'GZR', 'ORR', 'OPR', 'OYR']\n",
        "\n",
        "\n",
        "**Size of files:**\n",
        "\n",
        "All files are 50 rows x 35 columns except continuouslyforanhour_22.csv, headache_52.csv, home_61.csv, and mom_82.csv which are 101 rows x 35 columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVqdAdxkr-U5",
        "colab_type": "text"
      },
      "source": [
        "**Steps:**\n",
        "\n",
        "1. Combine files\n",
        "2. Normalize or standardize matrix\n",
        "3. Apply Butterworth\n",
        "4. Apply PCA\n",
        "5. Input to SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gca7rp-1Gimq",
        "colab_type": "text"
      },
      "source": [
        "# **1. Preparation of data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXI1GgkfFdai",
        "colab_type": "text"
      },
      "source": [
        "**1.1. Start up and initialization of variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TnTycFtrpHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import warnings\n",
        "\n",
        "from google.colab import files\n",
        "from mpl_toolkits import mplot3d\n",
        "from scipy import signal\n",
        "from scipy.io import loadmat\n",
        "from sklearn import metrics\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Extract all files from zip\n",
        "with ZipFile(\"/content/2MyoASL.zip\", 'r') as zip:\n",
        "  zip.extractall()\n",
        "\n",
        "products=[3, 5, 7, 11, 15, 21, 33, 35, 55, 77, 105, 165, 231, 385, 1155] # Generate matrices for all combinations of sensors (E=3, A=5, G=7, O=11)\n",
        "steps=[13, 39, 65, 91, 143, 273, 429, 455, 715, 1001, 3003, 5005] # Generate matrices for all combinations of steps (Normalization=3, Standardization=5, Butterworth=7, PCA=11, SVM=13)\n",
        "emg=['EMG0L', 'EMG1L', 'EMG2L', 'EMG3L', 'EMG4L', 'EMG5L', 'EMG6L', 'EMG7L', \n",
        "     'EMG0R', 'EMG1R', 'EMG2R', 'EMG3R', 'EMG4R', 'EMG5R', 'EMG6R', 'EMG7R']\n",
        "acc=['AXL', 'AYL', 'AZL', 'AXR', 'AYR', 'AZR']\n",
        "gyro=['GXL', 'GYL', 'GZL', 'GXR', 'GYR', 'GZR']\n",
        "ori=['ORL', 'OPL', 'OYL', 'ORR', 'OPR', 'OYR']\n",
        "\n",
        "# Initialization of counters\n",
        "words=['allmorning', 'bird', 'blue', 'cantsleep', 'cat', 'coldrunnynose', 'continuouslyforanhour', 'cost', 'day', \n",
        "       'dollar', 'everymorning', 'everynight', 'gold', 'goodnight', 'happy', 'headache', 'home', 'horse', 'hot', \n",
        "       'hurt', 'itching', 'large', 'mom', 'monthly', 'notfeelgood', 'orange', 'pizza', 'please', 'shirt', \n",
        "       'soreness', 'swelling', 'takeliquidmedicine', 'thatsterrible', 'tired', 'upsetstomach', 'wash']\n",
        "colnames=emg[:8]+acc[:3]+gyro[:3]+ori[:3]+emg[8:]+acc[3:]+gyro[3:]+ori[3:]\n",
        "lengths=np.zeros(849, dtype=int)\n",
        "reps=np.zeros(36,dtype=int)\n",
        "repsum=np.zeros(37,dtype=int)\n",
        "headers=np.empty(1701, dtype=object)\n",
        "features=np.zeros(15)\n",
        "target=np.zeros(15)\n",
        "matrix=np.zeros(1)\n",
        "norm=[]\n",
        "stand=[]\n",
        "\n",
        "fn=np.arange(1701)\n",
        "wordnum=-1\n",
        "counter=-1\n",
        "start=0\n",
        "num=0\n",
        "n=0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAKRziACFoe0",
        "colab_type": "text"
      },
      "source": [
        "**1.2. Combine all files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQFtofv7yG7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "9d3891a9-bb8f-4101-8c60-ae222efc667f"
      },
      "source": [
        "for w in words:\n",
        "  repcount=0\n",
        "  wordnum+=1\n",
        "  for i in range (10, 120):\n",
        "    path='/content/2MyoASL/' + w + '_' + str(i) + '.csv'\n",
        "    if os.path.exists(path)==True:\n",
        "      counter+=1\n",
        "      repcount+=1\n",
        "      trial=pd.read_csv(path)\n",
        "      trial.reset_index(drop=True)\n",
        "      \n",
        "      # Assign word number to one row\n",
        "      row=np.zeros(1)\n",
        "      for t in range(35):\n",
        "        if t==0:\n",
        "          row[0]=wordnum\n",
        "        else:\n",
        "          sensor=trial.iloc[0:50,t].values\n",
        "          sensor.reshape([1,50])\n",
        "          row=np.concatenate((row, sensor))\n",
        "      prev=row\n",
        "      \n",
        "      # Combine all trials\n",
        "      if counter==0:\n",
        "        matrix=prev\n",
        "      else:\n",
        "        matrix=np.concatenate([matrix,prev])\n",
        "\n",
        "  reps[wordnum]=repcount\n",
        "  if wordnum>0:\n",
        "    repsum[wordnum]=reps[wordnum-1]+repsum[wordnum-1]\n",
        "    repsum[36]=849\n",
        "\n",
        "# Create header name array\n",
        "headers[0]='Word'\n",
        "for c in colnames:\n",
        "  for t in range(50):\n",
        "    num+=1\n",
        "    headers[num]=c\n",
        "\n",
        "# Give format to final matrix \n",
        "matrix=matrix.reshape([849,1701])\n",
        "matrix=pd.DataFrame(matrix, columns=headers)\n",
        "matrix.to_csv(path_or_buf='/content/matrix.csv')\n",
        "print(matrix)\n",
        "print('Reps of each word:',reps)\n",
        "print('Cummulative reps:',repsum)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Word  EMG0L  EMG0L  EMG0L  EMG0L  ...    OYR    OYR    OYR    OYR    OYR\n",
            "0     0.0    0.0    0.0   -3.0   -1.0  ...   83.0   83.0   83.0   83.0   83.0\n",
            "1     0.0    0.0    0.0    4.0   -2.0  ...   83.0   83.0   83.0   83.0   83.0\n",
            "2     0.0    0.0    0.0   -8.0   -1.0  ...   84.0   84.0   84.0   84.0   84.0\n",
            "3     0.0    0.0    0.0   -1.0  -19.0  ...   83.0   83.0   83.0   83.0   83.0\n",
            "4     0.0    0.0    0.0    1.0  -16.0  ...   93.0   91.0   91.0   91.0   91.0\n",
            "..    ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
            "844  35.0    0.0    0.0   -2.0    0.0  ...  106.0  104.0  100.0   98.0   95.0\n",
            "845  35.0    0.0    0.0    2.0   -8.0  ...  176.0  176.0  177.0  177.0  177.0\n",
            "846  35.0    0.0    0.0   -8.0   26.0  ...  177.0  176.0  175.0  175.0  176.0\n",
            "847  35.0    0.0    0.0   -1.0   21.0  ...  178.0  178.0  179.0  179.0  179.0\n",
            "848  35.0    0.0    0.0    8.0  -19.0  ...  179.0  179.0  179.0  179.0    0.0\n",
            "\n",
            "[849 rows x 1701 columns]\n",
            "Reps of each word: [19 24 32 20 24 20 19 31 24 29 20 21 23 33 34 18 27 24 35 19 17 34 30 19\n",
            " 22 21 23 27 27  4 20 19 20 20 21 29]\n",
            "Cummulative reps: [  0  19  43  75  95 119 139 158 189 213 242 262 283 306 339 373 391 418\n",
            " 442 477 496 513 547 577 596 618 639 662 689 716 720 740 759 779 799 820\n",
            " 849]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaKAX2XvGL3O",
        "colab_type": "text"
      },
      "source": [
        "**1.3. Calculate mean and standard deviation of each sensor and each file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaytNKUWGo7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "115f4198-759c-47df-bc3f-3aa1abda4a8b"
      },
      "source": [
        "# Average and standard deviation of each sensor in each file\n",
        "for s in colnames:\n",
        "  avg=matrix[s].mean(axis=1)\n",
        "  sd=matrix[s].std(axis=1)\n",
        "  sensor=pd.concat([avg.rename(s+': Mean_'),sd.rename('St. dev.')], axis=1)\n",
        "  if s=='EMG0L':\n",
        "    asd=sensor\n",
        "  else:\n",
        "    asd=pd.concat([asd, sensor], axis=1)\n",
        "print(asd)\n",
        "\n",
        "# Average and standard deviation of each file\n",
        "avg=matrix.mean(axis=1)\n",
        "sd=matrix.std(axis=1)\n",
        "pd.concat([avg.rename('Mean'),sd.rename('St. dev.')], axis=1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     EMG0L: Mean_   St. dev.  EMG1L: Mean_  ...   St. dev.  OYR: Mean_   St. dev.\n",
            "0           -2.32   8.664825         -0.80  ...  28.427609       86.70  10.529356\n",
            "1           -1.80   9.544739         -4.08  ...  27.821010       85.68   6.579002\n",
            "2           -3.16  13.085839         -2.32  ...  30.345736       91.88  17.358924\n",
            "3           -0.82  10.123099         -3.16  ...  29.645002       88.46  12.969682\n",
            "4           -0.50   6.516071          2.76  ...  13.237239      116.58  18.099600\n",
            "..            ...        ...           ...  ...        ...         ...        ...\n",
            "844          0.56   7.754288          0.22  ...  17.236281      104.76   7.528341\n",
            "845         -1.74   6.520955         -1.20  ...  21.772891       69.66  85.251036\n",
            "846          1.02   7.731436          0.46  ...  22.707735       56.76  79.408415\n",
            "847          0.06   5.582078          2.36  ...  23.650422       71.62  84.238701\n",
            "848         -2.22   7.434860         -1.62  ...  25.101622       58.52  79.668763\n",
            "\n",
            "[849 rows x 68 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean</th>\n",
              "      <th>St. dev.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.256437</td>\n",
              "      <td>46.545832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.220110</td>\n",
              "      <td>47.316822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15.441784</td>\n",
              "      <td>45.614456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.651092</td>\n",
              "      <td>47.038916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15.063294</td>\n",
              "      <td>49.105612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>844</th>\n",
              "      <td>13.167964</td>\n",
              "      <td>41.642351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>13.815314</td>\n",
              "      <td>42.880121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>12.970618</td>\n",
              "      <td>42.725653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>13.852317</td>\n",
              "      <td>43.758631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>13.144035</td>\n",
              "      <td>44.761750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>849 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Mean   St. dev.\n",
              "0    15.256437  46.545832\n",
              "1    14.220110  47.316822\n",
              "2    15.441784  45.614456\n",
              "3    13.651092  47.038916\n",
              "4    15.063294  49.105612\n",
              "..         ...        ...\n",
              "844  13.167964  41.642351\n",
              "845  13.815314  42.880121\n",
              "846  12.970618  42.725653\n",
              "847  13.852317  43.758631\n",
              "848  13.144035  44.761750\n",
              "\n",
              "[849 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aFRMDnxG3yZ",
        "colab_type": "text"
      },
      "source": [
        "**1.4. Establish equal number of repetitions per word**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLze9It2KrBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "217cf0cc-227f-4bf5-e8c6-513228375db1"
      },
      "source": [
        "# Ensure all words have same number of repetitions\n",
        "numreps=20\n",
        "\n",
        "for i in range(len(reps)-1,-1,-1):\n",
        "  tl=sd.iloc[repsum[i]:repsum[i+1]]\n",
        "  u=repsum[i+1]-1\n",
        "  if reps[i]<numreps:\n",
        "    for r in range(len(matrix)-1,-1,-1):\n",
        "      if int(matrix.iloc[r]['Word'])==i:\n",
        "        matrix=matrix.drop(r)\n",
        "  elif reps[i]>numreps:\n",
        "    while reps[i]>numreps:\n",
        "      if tl[u]==tl.max():\n",
        "        tl[u]=0\n",
        "        matrix=matrix.drop(u)\n",
        "        reps[i]=reps[i]-1\n",
        "        u=repsum[i+1]-1\n",
        "      else:\n",
        "        u-=1\n",
        "\n",
        "print(matrix)\n",
        "print('Repetitions per word:',reps)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Word  EMG0L  EMG0L  EMG0L  EMG0L  ...    OYR    OYR    OYR    OYR    OYR\n",
            "23    1.0    0.0    0.0   -1.0   -1.0  ...  170.0  170.0  170.0  170.0  170.0\n",
            "24    1.0    0.0    0.0    0.0   -2.0  ...  178.0  179.0  179.0  179.0  179.0\n",
            "25    1.0    0.0    0.0   -1.0   -1.0  ...  177.0  177.0  177.0  177.0  177.0\n",
            "26    1.0    0.0    0.0   -1.0   -1.0  ...  179.0  179.0  179.0    0.0    0.0\n",
            "27    1.0    0.0    0.0   -1.0    0.0  ...   68.0   64.0   61.0   58.0   57.0\n",
            "..    ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
            "842  35.0    0.0    0.0   -1.0   -4.0  ...  103.0  102.0  100.0   97.0   95.0\n",
            "843  35.0    0.0    0.0    7.0    6.0  ...  100.0   98.0   95.0   94.0   92.0\n",
            "844  35.0    0.0    0.0   -2.0    0.0  ...  106.0  104.0  100.0   98.0   95.0\n",
            "845  35.0    0.0    0.0    2.0   -8.0  ...  176.0  176.0  177.0  177.0  177.0\n",
            "846  35.0    0.0    0.0   -8.0   26.0  ...  177.0  176.0  175.0  175.0  176.0\n",
            "\n",
            "[560 rows x 1701 columns]\n",
            "Repetitions per word: [19 20 20 20 20 20 19 20 20 20 20 20 20 20 20 18 20 20 20 19 17 20 20 19\n",
            " 20 20 20 20 20  4 20 19 20 20 20 20]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv_VaSCnHJYz",
        "colab_type": "text"
      },
      "source": [
        "**1.5. Create sensor combinatory matrices: unaltered, normalized, and standardized**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7Ib41KW5f32",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "881bac01-0c28-4dfe-93f5-3535c96b36ab"
      },
      "source": [
        "# Eliminate unnecessary columns to create combinatory matrices\n",
        "for v in products:\n",
        "  m=matrix.copy()\n",
        "  if v%3!=0:\n",
        "    m=m.drop(emg,1)\n",
        "  if v%5!=0:\n",
        "    m=m.drop(acc,1)\n",
        "  if v%7!=0:\n",
        "    m=m.drop(gyro,1)\n",
        "  if v%11!=0:\n",
        "    m=m.drop(ori,1)\n",
        "  products[n]=m.copy()\n",
        "  \n",
        "  # Normalize and Standardize each of the 15 matrices\n",
        "  # Separate features from target values\n",
        "  x = m.iloc[:, m.columns!='Word']   # Features\n",
        "  wordcol=np.empty(len(m), dtype=object)\n",
        "  z=0\n",
        "  wcol=[int(i) for i in m['Word'].values]\n",
        "  for f in wcol:\n",
        "    wordcol[z]=words[f]\n",
        "    z+=1\n",
        "  wordcol=np.asmatrix(wordcol)\n",
        " \n",
        "  ## Normalize features so that each column is between 0 and 1\n",
        "  norm_matrix=(m-m.min())/(m.max()-m.min())\n",
        "  norm_matrix=np.concatenate((np.transpose(wordcol),norm_matrix.iloc[:,1:]),axis=1)\n",
        "  norm_matrix=pd.DataFrame(norm_matrix,columns=m.columns).dropna(axis=1)\n",
        "  norm.append(norm_matrix)\n",
        "  \n",
        "  ## Standardize features with mean=0 and deviation=1\n",
        "  print('standard x:')\n",
        "  standardized_matrix=StandardScaler().fit_transform(x)\n",
        "  print(standardized_matrix)\n",
        "  print('standard m:')\n",
        "  st_matrix=StandardScaler().fit_transform(m)\n",
        "  print(st_matrix)\n",
        "  #standardized_matrix=np.concatenate((np.transpose(wordcol),standardized_matrix),axis=1)\n",
        "  #standardized_matrix=pd.DataFrame(standardized_matrix,columns=m.columns).dropna(axis=1)\n",
        "  #stand.append(standardized_matrix)\n",
        "  n+=1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "standard x:\n",
            "[[ 0.         -0.00744137 -0.0148686  ... -1.31914039 -0.07990451\n",
            "   0.23689767]\n",
            " [ 0.         -0.00744137  0.10580413 ...  0.29731173 -0.68663707\n",
            "  -0.73380499]\n",
            " [ 0.         -0.00744137 -0.0148686  ...  0.29731173  1.58861003\n",
            "  -0.08666988]\n",
            " ...\n",
            " [ 0.         -0.00744137 -0.13554134 ...  0.29731173  1.89197631\n",
            "  -1.54272387]\n",
            " [ 0.         -0.00744137  0.34714959 ...  0.00341134 -0.07990451\n",
            "  -0.24845366]\n",
            " [ 0.         -0.00744137 -0.85957773 ... -0.14353885  1.28524375\n",
            "  -0.41023743]]\n",
            "standard m:\n",
            "[[-1.56130578  0.         -0.00744137 ... -1.31914039 -0.07990451\n",
            "   0.23689767]\n",
            " [-1.56130578  0.         -0.00744137 ...  0.29731173 -0.68663707\n",
            "  -0.73380499]\n",
            " [-1.56130578  0.         -0.00744137 ...  0.29731173  1.58861003\n",
            "  -0.08666988]\n",
            " ...\n",
            " [ 1.67695806  0.         -0.00744137 ...  0.29731173  1.89197631\n",
            "  -1.54272387]\n",
            " [ 1.67695806  0.         -0.00744137 ...  0.00341134 -0.07990451\n",
            "  -0.24845366]\n",
            " [ 1.67695806  0.         -0.00744137 ... -0.14353885  1.28524375\n",
            "  -0.41023743]]\n",
            "standard x:\n",
            "[[ 1.16810988  1.06306475  1.01363479 ...  0.72237973  0.71531438\n",
            "   0.62453566]\n",
            " [ 1.13169122  1.06741488  0.94492414 ...  0.7147576   0.61010962\n",
            "   0.64064144]\n",
            " [ 1.15791254  1.07322101  0.98071008 ...  1.05264925  1.31497235\n",
            "   0.84462412]\n",
            " ...\n",
            " [-1.28214351 -1.45711769 -1.02044426 ...  0.61568039  0.47597369\n",
            "   0.41250009]\n",
            " [ 0.3639846   0.3521317  -0.12722344 ... -0.92636645 -1.33883131\n",
            "  -0.47322419]\n",
            " [-1.22824199 -1.06682956  0.12470934 ... -0.01943249  0.0419953\n",
            "  -0.47590665]]\n",
            "standard m:\n",
            "[[-1.56130578  1.16810988  1.06306475 ...  0.72237973  0.71531438\n",
            "   0.62453566]\n",
            " [-1.56130578  1.13169122  1.06741488 ...  0.7147576   0.61010962\n",
            "   0.64064144]\n",
            " [-1.56130578  1.15791254  1.07322101 ...  1.05264925  1.31497235\n",
            "   0.84462412]\n",
            " ...\n",
            " [ 1.67695806 -1.28214351 -1.45711769 ...  0.61568039  0.47597369\n",
            "   0.41250009]\n",
            " [ 1.67695806  0.3639846   0.3521317  ... -0.92636645 -1.33883131\n",
            "  -0.47322419]\n",
            " [ 1.67695806 -1.22824199 -1.06682956 ... -0.01943249  0.0419953\n",
            "  -0.47590665]]\n",
            "standard x:\n",
            "[[-7.19657768e-02  1.75172918e-02  1.74704706e-01 ...  4.87245812e-01\n",
            "   4.56719702e-01  5.03619101e-01]\n",
            " [ 4.74977359e-02  9.19866295e-02  5.35088080e-02 ...  4.76122590e-01\n",
            "   4.36460847e-01  4.30063859e-01]\n",
            " [-1.76641801e-02  2.28492722e-03 -6.93248728e-02 ...  4.22978306e-01\n",
            "   6.16258187e-01  5.69963045e-01]\n",
            " ...\n",
            " [-3.50925685e+00 -2.88678688e+00 -3.25808723e+00 ... -2.71006263e+00\n",
            "  -2.88599141e+00 -2.77031029e+00]\n",
            " [-2.09560528e+00 -2.11501374e+00 -5.14801688e-01 ...  6.34319528e-01\n",
            "   1.45239803e-01  4.89196505e-01]\n",
            " [-2.38490673e-01 -7.23791116e-01 -1.08802553e+00 ... -1.11573411e+00\n",
            "  -1.81434237e-01  2.52665923e-01]]\n",
            "standard m:\n",
            "[[-1.56130578e+00 -7.19657768e-02  1.75172918e-02 ...  4.87245812e-01\n",
            "   4.56719702e-01  5.03619101e-01]\n",
            " [-1.56130578e+00  4.74977359e-02  9.19866295e-02 ...  4.76122590e-01\n",
            "   4.36460847e-01  4.30063859e-01]\n",
            " [-1.56130578e+00 -1.76641801e-02  2.28492722e-03 ...  4.22978306e-01\n",
            "   6.16258187e-01  5.69963045e-01]\n",
            " ...\n",
            " [ 1.67695806e+00 -3.50925685e+00 -2.88678688e+00 ... -2.71006263e+00\n",
            "  -2.88599141e+00 -2.77031029e+00]\n",
            " [ 1.67695806e+00 -2.09560528e+00 -2.11501374e+00 ...  6.34319528e-01\n",
            "   1.45239803e-01  4.89196505e-01]\n",
            " [ 1.67695806e+00 -2.38490673e-01 -7.23791116e-01 ... -1.11573411e+00\n",
            "  -1.81434237e-01  2.52665923e-01]]\n",
            "standard x:\n",
            "[[ 0.86152526  0.86604448  0.86077737 ...  2.02130933  2.02410232\n",
            "   2.02480854]\n",
            " [ 0.7658382   0.7705186   0.76674005 ...  2.21944994  2.22277173\n",
            "   2.22393895]\n",
            " [ 0.7658382   0.7705186   0.76674005 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " ...\n",
            " [-0.86084178 -0.9489473  -1.39611843 ...  0.48021576  0.43474701\n",
            "   0.36538849]\n",
            " [-1.24359001 -1.33105084 -1.49015575 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " [-1.05221589 -1.04447319 -1.3020811  ...  2.13138745  2.13447421\n",
            "   2.15756214]]\n",
            "standard m:\n",
            "[[-1.56130578  0.86152526  0.86604448 ...  2.02130933  2.02410232\n",
            "   2.02480854]\n",
            " [-1.56130578  0.7658382   0.7705186  ...  2.21944994  2.22277173\n",
            "   2.22393895]\n",
            " [-1.56130578  0.7658382   0.7705186  ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " ...\n",
            " [ 1.67695806 -0.86084178 -0.9489473  ...  0.48021576  0.43474701\n",
            "   0.36538849]\n",
            " [ 1.67695806 -1.24359001 -1.33105084 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " [ 1.67695806 -1.05221589 -1.04447319 ...  2.13138745  2.13447421\n",
            "   2.15756214]]\n",
            "standard x:\n",
            "[[ 0.         -0.00744137 -0.0148686  ...  0.72237973  0.71531438\n",
            "   0.62453566]\n",
            " [ 0.         -0.00744137  0.10580413 ...  0.7147576   0.61010962\n",
            "   0.64064144]\n",
            " [ 0.         -0.00744137 -0.0148686  ...  1.05264925  1.31497235\n",
            "   0.84462412]\n",
            " ...\n",
            " [ 0.         -0.00744137 -0.13554134 ...  0.61568039  0.47597369\n",
            "   0.41250009]\n",
            " [ 0.         -0.00744137  0.34714959 ... -0.92636645 -1.33883131\n",
            "  -0.47322419]\n",
            " [ 0.         -0.00744137 -0.85957773 ... -0.01943249  0.0419953\n",
            "  -0.47590665]]\n",
            "standard m:\n",
            "[[-1.56130578  0.         -0.00744137 ...  0.72237973  0.71531438\n",
            "   0.62453566]\n",
            " [-1.56130578  0.         -0.00744137 ...  0.7147576   0.61010962\n",
            "   0.64064144]\n",
            " [-1.56130578  0.         -0.00744137 ...  1.05264925  1.31497235\n",
            "   0.84462412]\n",
            " ...\n",
            " [ 1.67695806  0.         -0.00744137 ...  0.61568039  0.47597369\n",
            "   0.41250009]\n",
            " [ 1.67695806  0.         -0.00744137 ... -0.92636645 -1.33883131\n",
            "  -0.47322419]\n",
            " [ 1.67695806  0.         -0.00744137 ... -0.01943249  0.0419953\n",
            "  -0.47590665]]\n",
            "standard x:\n",
            "[[ 0.         -0.00744137 -0.0148686  ...  0.48724581  0.4567197\n",
            "   0.5036191 ]\n",
            " [ 0.         -0.00744137  0.10580413 ...  0.47612259  0.43646085\n",
            "   0.43006386]\n",
            " [ 0.         -0.00744137 -0.0148686  ...  0.42297831  0.61625819\n",
            "   0.56996304]\n",
            " ...\n",
            " [ 0.         -0.00744137 -0.13554134 ... -2.71006263 -2.88599141\n",
            "  -2.77031029]\n",
            " [ 0.         -0.00744137  0.34714959 ...  0.63431953  0.1452398\n",
            "   0.4891965 ]\n",
            " [ 0.         -0.00744137 -0.85957773 ... -1.11573411 -0.18143424\n",
            "   0.25266592]]\n",
            "standard m:\n",
            "[[-1.56130578  0.         -0.00744137 ...  0.48724581  0.4567197\n",
            "   0.5036191 ]\n",
            " [-1.56130578  0.         -0.00744137 ...  0.47612259  0.43646085\n",
            "   0.43006386]\n",
            " [-1.56130578  0.         -0.00744137 ...  0.42297831  0.61625819\n",
            "   0.56996304]\n",
            " ...\n",
            " [ 1.67695806  0.         -0.00744137 ... -2.71006263 -2.88599141\n",
            "  -2.77031029]\n",
            " [ 1.67695806  0.         -0.00744137 ...  0.63431953  0.1452398\n",
            "   0.4891965 ]\n",
            " [ 1.67695806  0.         -0.00744137 ... -1.11573411 -0.18143424\n",
            "   0.25266592]]\n",
            "standard x:\n",
            "[[ 0.         -0.00744137 -0.0148686  ...  2.02130933  2.02410232\n",
            "   2.02480854]\n",
            " [ 0.         -0.00744137  0.10580413 ...  2.21944994  2.22277173\n",
            "   2.22393895]\n",
            " [ 0.         -0.00744137 -0.0148686  ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " ...\n",
            " [ 0.         -0.00744137 -0.13554134 ...  0.48021576  0.43474701\n",
            "   0.36538849]\n",
            " [ 0.         -0.00744137  0.34714959 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " [ 0.         -0.00744137 -0.85957773 ...  2.13138745  2.13447421\n",
            "   2.15756214]]\n",
            "standard m:\n",
            "[[-1.56130578  0.         -0.00744137 ...  2.02130933  2.02410232\n",
            "   2.02480854]\n",
            " [-1.56130578  0.         -0.00744137 ...  2.21944994  2.22277173\n",
            "   2.22393895]\n",
            " [-1.56130578  0.         -0.00744137 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " ...\n",
            " [ 1.67695806  0.         -0.00744137 ...  0.48021576  0.43474701\n",
            "   0.36538849]\n",
            " [ 1.67695806  0.         -0.00744137 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " [ 1.67695806  0.         -0.00744137 ...  2.13138745  2.13447421\n",
            "   2.15756214]]\n",
            "standard x:\n",
            "[[ 1.16810988  1.06306475  1.01363479 ...  0.48724581  0.4567197\n",
            "   0.5036191 ]\n",
            " [ 1.13169122  1.06741488  0.94492414 ...  0.47612259  0.43646085\n",
            "   0.43006386]\n",
            " [ 1.15791254  1.07322101  0.98071008 ...  0.42297831  0.61625819\n",
            "   0.56996304]\n",
            " ...\n",
            " [-1.28214351 -1.45711769 -1.02044426 ... -2.71006263 -2.88599141\n",
            "  -2.77031029]\n",
            " [ 0.3639846   0.3521317  -0.12722344 ...  0.63431953  0.1452398\n",
            "   0.4891965 ]\n",
            " [-1.22824199 -1.06682956  0.12470934 ... -1.11573411 -0.18143424\n",
            "   0.25266592]]\n",
            "standard m:\n",
            "[[-1.56130578  1.16810988  1.06306475 ...  0.48724581  0.4567197\n",
            "   0.5036191 ]\n",
            " [-1.56130578  1.13169122  1.06741488 ...  0.47612259  0.43646085\n",
            "   0.43006386]\n",
            " [-1.56130578  1.15791254  1.07322101 ...  0.42297831  0.61625819\n",
            "   0.56996304]\n",
            " ...\n",
            " [ 1.67695806 -1.28214351 -1.45711769 ... -2.71006263 -2.88599141\n",
            "  -2.77031029]\n",
            " [ 1.67695806  0.3639846   0.3521317  ...  0.63431953  0.1452398\n",
            "   0.4891965 ]\n",
            " [ 1.67695806 -1.22824199 -1.06682956 ... -1.11573411 -0.18143424\n",
            "   0.25266592]]\n",
            "standard x:\n",
            "[[ 1.16810988  1.06306475  1.01363479 ...  2.02130933  2.02410232\n",
            "   2.02480854]\n",
            " [ 1.13169122  1.06741488  0.94492414 ...  2.21944994  2.22277173\n",
            "   2.22393895]\n",
            " [ 1.15791254  1.07322101  0.98071008 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " ...\n",
            " [-1.28214351 -1.45711769 -1.02044426 ...  0.48021576  0.43474701\n",
            "   0.36538849]\n",
            " [ 0.3639846   0.3521317  -0.12722344 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " [-1.22824199 -1.06682956  0.12470934 ...  2.13138745  2.13447421\n",
            "   2.15756214]]\n",
            "standard m:\n",
            "[[-1.56130578  1.16810988  1.06306475 ...  2.02130933  2.02410232\n",
            "   2.02480854]\n",
            " [-1.56130578  1.13169122  1.06741488 ...  2.21944994  2.22277173\n",
            "   2.22393895]\n",
            " [-1.56130578  1.15791254  1.07322101 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " ...\n",
            " [ 1.67695806 -1.28214351 -1.45711769 ...  0.48021576  0.43474701\n",
            "   0.36538849]\n",
            " [ 1.67695806  0.3639846   0.3521317  ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " [ 1.67695806 -1.22824199 -1.06682956 ...  2.13138745  2.13447421\n",
            "   2.15756214]]\n",
            "standard x:\n",
            "[[-7.19657768e-02  1.75172918e-02  1.74704706e-01 ...  2.02130933e+00\n",
            "   2.02410232e+00  2.02480854e+00]\n",
            " [ 4.74977359e-02  9.19866295e-02  5.35088080e-02 ...  2.21944994e+00\n",
            "   2.22277173e+00  2.22393895e+00]\n",
            " [-1.76641801e-02  2.28492722e-03 -6.93248728e-02 ...  2.17541869e+00\n",
            "   2.17862297e+00  2.17968775e+00]\n",
            " ...\n",
            " [-3.50925685e+00 -2.88678688e+00 -3.25808723e+00 ...  4.80215764e-01\n",
            "   4.34747015e-01  3.65388491e-01]\n",
            " [-2.09560528e+00 -2.11501374e+00 -5.14801688e-01 ...  2.17541869e+00\n",
            "   2.17862297e+00  2.17968775e+00]\n",
            " [-2.38490673e-01 -7.23791116e-01 -1.08802553e+00 ...  2.13138745e+00\n",
            "   2.13447421e+00  2.15756214e+00]]\n",
            "standard m:\n",
            "[[-1.56130578e+00 -7.19657768e-02  1.75172918e-02 ...  2.02130933e+00\n",
            "   2.02410232e+00  2.02480854e+00]\n",
            " [-1.56130578e+00  4.74977359e-02  9.19866295e-02 ...  2.21944994e+00\n",
            "   2.22277173e+00  2.22393895e+00]\n",
            " [-1.56130578e+00 -1.76641801e-02  2.28492722e-03 ...  2.17541869e+00\n",
            "   2.17862297e+00  2.17968775e+00]\n",
            " ...\n",
            " [ 1.67695806e+00 -3.50925685e+00 -2.88678688e+00 ...  4.80215764e-01\n",
            "   4.34747015e-01  3.65388491e-01]\n",
            " [ 1.67695806e+00 -2.09560528e+00 -2.11501374e+00 ...  2.17541869e+00\n",
            "   2.17862297e+00  2.17968775e+00]\n",
            " [ 1.67695806e+00 -2.38490673e-01 -7.23791116e-01 ...  2.13138745e+00\n",
            "   2.13447421e+00  2.15756214e+00]]\n",
            "standard x:\n",
            "[[ 0.         -0.00744137 -0.0148686  ...  0.48724581  0.4567197\n",
            "   0.5036191 ]\n",
            " [ 0.         -0.00744137  0.10580413 ...  0.47612259  0.43646085\n",
            "   0.43006386]\n",
            " [ 0.         -0.00744137 -0.0148686  ...  0.42297831  0.61625819\n",
            "   0.56996304]\n",
            " ...\n",
            " [ 0.         -0.00744137 -0.13554134 ... -2.71006263 -2.88599141\n",
            "  -2.77031029]\n",
            " [ 0.         -0.00744137  0.34714959 ...  0.63431953  0.1452398\n",
            "   0.4891965 ]\n",
            " [ 0.         -0.00744137 -0.85957773 ... -1.11573411 -0.18143424\n",
            "   0.25266592]]\n",
            "standard m:\n",
            "[[-1.56130578  0.         -0.00744137 ...  0.48724581  0.4567197\n",
            "   0.5036191 ]\n",
            " [-1.56130578  0.         -0.00744137 ...  0.47612259  0.43646085\n",
            "   0.43006386]\n",
            " [-1.56130578  0.         -0.00744137 ...  0.42297831  0.61625819\n",
            "   0.56996304]\n",
            " ...\n",
            " [ 1.67695806  0.         -0.00744137 ... -2.71006263 -2.88599141\n",
            "  -2.77031029]\n",
            " [ 1.67695806  0.         -0.00744137 ...  0.63431953  0.1452398\n",
            "   0.4891965 ]\n",
            " [ 1.67695806  0.         -0.00744137 ... -1.11573411 -0.18143424\n",
            "   0.25266592]]\n",
            "standard x:\n",
            "[[ 0.         -0.00744137 -0.0148686  ...  2.02130933  2.02410232\n",
            "   2.02480854]\n",
            " [ 0.         -0.00744137  0.10580413 ...  2.21944994  2.22277173\n",
            "   2.22393895]\n",
            " [ 0.         -0.00744137 -0.0148686  ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " ...\n",
            " [ 0.         -0.00744137 -0.13554134 ...  0.48021576  0.43474701\n",
            "   0.36538849]\n",
            " [ 0.         -0.00744137  0.34714959 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " [ 0.         -0.00744137 -0.85957773 ...  2.13138745  2.13447421\n",
            "   2.15756214]]\n",
            "standard m:\n",
            "[[-1.56130578  0.         -0.00744137 ...  2.02130933  2.02410232\n",
            "   2.02480854]\n",
            " [-1.56130578  0.         -0.00744137 ...  2.21944994  2.22277173\n",
            "   2.22393895]\n",
            " [-1.56130578  0.         -0.00744137 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " ...\n",
            " [ 1.67695806  0.         -0.00744137 ...  0.48021576  0.43474701\n",
            "   0.36538849]\n",
            " [ 1.67695806  0.         -0.00744137 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " [ 1.67695806  0.         -0.00744137 ...  2.13138745  2.13447421\n",
            "   2.15756214]]\n",
            "standard x:\n",
            "[[ 0.         -0.00744137 -0.0148686  ...  2.02130933  2.02410232\n",
            "   2.02480854]\n",
            " [ 0.         -0.00744137  0.10580413 ...  2.21944994  2.22277173\n",
            "   2.22393895]\n",
            " [ 0.         -0.00744137 -0.0148686  ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " ...\n",
            " [ 0.         -0.00744137 -0.13554134 ...  0.48021576  0.43474701\n",
            "   0.36538849]\n",
            " [ 0.         -0.00744137  0.34714959 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " [ 0.         -0.00744137 -0.85957773 ...  2.13138745  2.13447421\n",
            "   2.15756214]]\n",
            "standard m:\n",
            "[[-1.56130578  0.         -0.00744137 ...  2.02130933  2.02410232\n",
            "   2.02480854]\n",
            " [-1.56130578  0.         -0.00744137 ...  2.21944994  2.22277173\n",
            "   2.22393895]\n",
            " [-1.56130578  0.         -0.00744137 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " ...\n",
            " [ 1.67695806  0.         -0.00744137 ...  0.48021576  0.43474701\n",
            "   0.36538849]\n",
            " [ 1.67695806  0.         -0.00744137 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " [ 1.67695806  0.         -0.00744137 ...  2.13138745  2.13447421\n",
            "   2.15756214]]\n",
            "standard x:\n",
            "[[ 1.16810988  1.06306475  1.01363479 ...  2.02130933  2.02410232\n",
            "   2.02480854]\n",
            " [ 1.13169122  1.06741488  0.94492414 ...  2.21944994  2.22277173\n",
            "   2.22393895]\n",
            " [ 1.15791254  1.07322101  0.98071008 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " ...\n",
            " [-1.28214351 -1.45711769 -1.02044426 ...  0.48021576  0.43474701\n",
            "   0.36538849]\n",
            " [ 0.3639846   0.3521317  -0.12722344 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " [-1.22824199 -1.06682956  0.12470934 ...  2.13138745  2.13447421\n",
            "   2.15756214]]\n",
            "standard m:\n",
            "[[-1.56130578  1.16810988  1.06306475 ...  2.02130933  2.02410232\n",
            "   2.02480854]\n",
            " [-1.56130578  1.13169122  1.06741488 ...  2.21944994  2.22277173\n",
            "   2.22393895]\n",
            " [-1.56130578  1.15791254  1.07322101 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " ...\n",
            " [ 1.67695806 -1.28214351 -1.45711769 ...  0.48021576  0.43474701\n",
            "   0.36538849]\n",
            " [ 1.67695806  0.3639846   0.3521317  ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " [ 1.67695806 -1.22824199 -1.06682956 ...  2.13138745  2.13447421\n",
            "   2.15756214]]\n",
            "standard x:\n",
            "[[ 0.         -0.00744137 -0.0148686  ...  2.02130933  2.02410232\n",
            "   2.02480854]\n",
            " [ 0.         -0.00744137  0.10580413 ...  2.21944994  2.22277173\n",
            "   2.22393895]\n",
            " [ 0.         -0.00744137 -0.0148686  ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " ...\n",
            " [ 0.         -0.00744137 -0.13554134 ...  0.48021576  0.43474701\n",
            "   0.36538849]\n",
            " [ 0.         -0.00744137  0.34714959 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " [ 0.         -0.00744137 -0.85957773 ...  2.13138745  2.13447421\n",
            "   2.15756214]]\n",
            "standard m:\n",
            "[[-1.56130578  0.         -0.00744137 ...  2.02130933  2.02410232\n",
            "   2.02480854]\n",
            " [-1.56130578  0.         -0.00744137 ...  2.21944994  2.22277173\n",
            "   2.22393895]\n",
            " [-1.56130578  0.         -0.00744137 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " ...\n",
            " [ 1.67695806  0.         -0.00744137 ...  0.48021576  0.43474701\n",
            "   0.36538849]\n",
            " [ 1.67695806  0.         -0.00744137 ...  2.17541869  2.17862297\n",
            "   2.17968775]\n",
            " [ 1.67695806  0.         -0.00744137 ...  2.13138745  2.13447421\n",
            "   2.15756214]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJtV04hjOid6",
        "colab_type": "text"
      },
      "source": [
        "# **2. Definition of functions for steps**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQF9gp3gVloy",
        "colab_type": "text"
      },
      "source": [
        "**2.1. Split data into train and test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfHNiVxNVvK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def datasplit(inmatrix_p):\n",
        "    x = inmatrix_p.iloc[:, inmatrix_p.columns!='Word']   # Features\n",
        "    y = inmatrix_p.loc[:,'Word']     # Target\n",
        "    x_train_p, x_test_p, y_train_p, y_test_p = train_test_split(x, y, test_size=0.6)\n",
        "    return x_train_p, x_test_p, y_train_p, y_test_p"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGLs1pC8Vg15",
        "colab_type": "text"
      },
      "source": [
        "**2.2. Butterworth**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJjGC_1Q5r03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def butterworth(inmatrix_b):\n",
        "  high = 1/(50/2)\n",
        "  low = 23/(50/2)\n",
        "\n",
        "  b, a = sp.signal.butter(4, [high,low], btype='bandpass')\n",
        "\n",
        "  for r in emg:\n",
        "    if r in inmatrix_b:\n",
        "      # process EMG signal: filter EMG\n",
        "      emg_filtered = sp.signal.lfilter(b, a, inmatrix_b[[r]])\n",
        "      inmatrix_b[[r]]=emg_filtered\n",
        "  return inmatrix_b"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxsIrFj9V7SX",
        "colab_type": "text"
      },
      "source": [
        "**2.3. PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7WTmphBWFnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pca(x_train_c, x_test_c, y_train_c, y_test_c):\n",
        "  pca = PCA(n_components=100)\n",
        "  pca.fit(x_train_c)\n",
        "  x_t_train_pca = pca.transform(x_train_c)\n",
        "  x_t_test_pca = pca.transform(x_test_c)\n",
        "\n",
        "  # Plot\n",
        "  #print(\"Normalized matrix\")\n",
        "  #print(pca.explained_variance_ratio_)\n",
        "  #print(pca.singular_values_)\n",
        "  #plt.figure()\n",
        "  #plt.bar(fn[:100], pca.explained_variance_ratio_)\n",
        "  #plt.show()\n",
        "  #plt.bar(fn[:100], pca.singular_values_)\n",
        "  #plt.show()\n",
        "  return x_train_c, x_test_c, y_train_c, y_test_c, x_t_train_pca, x_t_test_pca"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrXL60g9WO_M",
        "colab_type": "text"
      },
      "source": [
        "**2.4. SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz0otyHbWRRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def svm(x_train_s, x_test_s, y_train_s, y_test_s, x_t_train_s=\"\", x_t_test_s=\"\"):\n",
        "    if x_t_train_s==\"\":\n",
        "      x_t_train_s=x_train_s\n",
        "    if x_t_test_s==\"\":\n",
        "      x_t_test_s=x_test_s\n",
        "    clf = SVC()\n",
        "    clf.fit(x_t_train_s, y_train_s)\n",
        "    #print('score', clf.score(x_t_test_s, y_test_s))\n",
        "    y_pred=clf.predict(x_t_test_s)\n",
        "    #print('pred label', y_pred)\n",
        "    #print('length',len(clf.predict(x_t_test_s)))\n",
        "\n",
        "    # Confusion matrix\n",
        "    #plot_confusion_matrix(clf, x_t_test_s, y_test_s,cmap=plt.cm.Blues)\n",
        "    #plt.figure(figsize=(50,50))\n",
        "    #plt.show()\n",
        "\n",
        "    accuracy=clf.score(x_t_test_s, y_test_s)\n",
        "    svmresult=classification_report(y_test_s, y_pred, target_names=words)\n",
        "    return svmresult,accuracy"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKoS0bOpWV7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "523ce195-7d77-4c79-f8f4-07bd2cb5e183"
      },
      "source": [
        "for l in products:\n",
        "  words=set(l['Word'])\n",
        "  if v%3=0: # Normalization\n",
        "    m=m.drop(emg,1)\n",
        "  if v%5=0: # Standardization\n",
        "    m=m.drop(acc,1)\n",
        "  if v%7=0: # Butterworth\n",
        "    m=m.drop(gyro,1)\n",
        "  if v%11=0: # PCA\n",
        "    m=m.drop(ori,1)\n",
        "  if v%13=0: # SVM\n",
        "    m=m.drop(ori,1)\n",
        "\n",
        "\n",
        "for u in norm:\n",
        "  words=set(u['Word'])\n",
        "  x_train, x_test, y_train, y_test=datasplit(butterworth(u))\n",
        "  x_train_c, x_test_c, y_train_c, y_test_c, x_t_train_pca, x_t_test_pca=pca(x_train, x_test, y_train, y_test)\n",
        "  svmresults,accuracy=svm(x_train_c, x_test_c, y_train_c, y_test_c, x_t_train_pca, x_t_test_pca)\n",
        "  print('The results are',accuracy)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-637b65d91477>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    if v%3=0: # Normalization\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHvbT3DjWHXr",
        "colab_type": "text"
      },
      "source": [
        "Original code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oegUzb00nsA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Butterworth\n",
        "#high = 20/(1000/2)\n",
        "#low = 450/(1000/2)\n",
        "high = 1/(50/2)\n",
        "low = 23/(50/2)\n",
        "\n",
        "b, a = sp.signal.butter(4, [high,low], btype='bandpass')\n",
        "\n",
        "for r in emg:\n",
        "  norm_matrix_eago[[r]]\n",
        "  # process EMG signal: filter EMG\n",
        "  emg_filtered = sp.signal.lfilter(b, a, norm_matrix_eago[[r]])\n",
        "  norm_matrix_eago[[r]]=emg_filtered\n",
        "\n",
        "buttermatrix=norm_matrix_eago"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I16C6HCyrFZr",
        "colab_type": "text"
      },
      "source": [
        "**Combinations of steps for classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw8kyulNOsmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directly to SVM\n",
        "x = attempt.iloc[:, attempt.columns!='Word'].values   # Features\n",
        "y = attempt.loc[:,'Word'].values     # Target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(x_train, y_train)\n",
        "print ('score', clf.score(x_test, y_test))\n",
        "y_pred=clf.predict(x_test)\n",
        "print ('pred label', y_pred)\n",
        "print('length',len(clf.predict(x_test)))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, x_test, y_test,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.figure(figsize=(50,50))\n",
        "plt.show()\n",
        "\n",
        "#print(classification_report(y_test, y_pred, target_names=words))\n",
        "directresults=classification_report(y_test, y_pred, target_names=set(attempt['Word']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgPwhYZvrn3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalized to SVM\n",
        "x = nmatrix.iloc[:, nmatrix.columns!='Word'].values   # Features\n",
        "y = nmatrix.loc[:,'Word'].values     # Target\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(x_train, y_train)\n",
        "print ('score', clf.score(x_test, y_test))\n",
        "y_pred=clf.predict(x_test)\n",
        "print ('pred label', y_pred)\n",
        "print('length',len(clf.predict(x_test)))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, x_test, y_test,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.figure(figsize=(50,50))\n",
        "plt.show()\n",
        "\n",
        "#print(classification_report(y_test, y_pred, target_names=words))\n",
        "normresults=classification_report(y_test, y_pred, target_names=words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OL74iKMnWZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalized, Butterworth to SVM\n",
        "x = buttermatrix.iloc[:, buttermatrix.columns!='Word'].values   # Features\n",
        "y = buttermatrix.loc[:,'Word'].values     # Target\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(x_train, y_train)\n",
        "print ('score', clf.score(x_test, y_test))\n",
        "y_pred=clf.predict(x_test)\n",
        "print ('pred label', y_pred)\n",
        "print('length',len(clf.predict(x_test)))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, x_test, y_test,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.figure(figsize=(50,50))\n",
        "plt.show()\n",
        "\n",
        "#print(classification_report(y_test, y_pred, target_names=words))\n",
        "butterresults=classification_report(y_test, y_pred, target_names=words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riv-kFwa9oMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PCA for norm_matrix\n",
        "\n",
        "x = norm_matrix_eago.iloc[:, norm_matrix_eago.columns!='Word'].values   # Features\n",
        "y = norm_matrix_eago.loc[:,'Word'].values     # Target\n",
        "print(y)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)\n",
        "\n",
        "pca = PCA(n_components=40)\n",
        "pca.fit(x_train)\n",
        "x_t_train = pca.transform(x_train)\n",
        "x_t_test = pca.transform(x_test)\n",
        "\n",
        "#### plot\n",
        "print(\"Normalized matrix\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn[:40],pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn[:40],pca.singular_values_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSevZSPDFZjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalized, Butterworth, PCA to SVM\n",
        "clf = SVC()\n",
        "clf.fit(x_t_train, y_train)\n",
        "print ('score', clf.score(x_t_test, y_test))\n",
        "y_pred=clf.predict(x_t_test)\n",
        "print ('pred label', y_pred)\n",
        "print('length',len(clf.predict(x_t_test)))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, x_t_test, y_test,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.figure(figsize=(50,50))\n",
        "plt.show()\n",
        "\n",
        "#print(classification_report(y_test, y_pred, target_names=words))\n",
        "pcaresults=classification_report(y_test, y_pred, target_names=words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPsmjnnASPYX",
        "colab_type": "text"
      },
      "source": [
        "**Summary of results**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGL1j6iBSlGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Directly:')\n",
        "print(directresults)\n",
        "print('Normalized:')\n",
        "print(normresults)\n",
        "print('Butterworth:')\n",
        "print(butterresults)\n",
        "print('PCA:')\n",
        "print(pcaresults)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h57zKLByfy2Y",
        "colab_type": "text"
      },
      "source": [
        "TODO:\n",
        "\n",
        "-check what happens when combining diff data sources\n",
        "\n",
        "-graph components\n",
        "\n",
        "find correlations\n",
        "\n",
        "-interpret pca results\n",
        "\n",
        "-try pca per individual/word\n",
        "\n",
        "-read dataset papers\n",
        "\n",
        "correlation component with word\n",
        "\n",
        "-try straight to svm\n",
        "\n",
        "-resend email\n",
        "\n",
        "check what is the data\n",
        "\n",
        "-merge timeseries word index\n",
        "\n",
        "see how stable each feature are\n",
        "\n",
        "standard deviation timeseries\n",
        "\n",
        "-try without filter\n",
        "\n",
        "multi-class classifier SVM\n",
        "\n",
        "**try with 2 words, only emg\n",
        "average per column\n",
        "test each step\n",
        "test svm with 2 matrices\n",
        "see if svm has access to test set \n",
        "maybe shifted per set \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScbnguG8ONoC",
        "colab_type": "text"
      },
      "source": [
        "https://www.researchgate.net/publication/303707429_Combining_Smartphone_and_Smartwatch_Sensor_Data_in_Activity_Recognition_Approaches_an_Experimental_Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay3NExQ59xrM",
        "colab_type": "text"
      },
      "source": [
        "References\n",
        "\n",
        "https://stackoverflow.com/questions/56449262/how-to-upload-folders-to-google-colab\n",
        "\n",
        "https://github.com/datarail/datarail/issues/39\n",
        "\n",
        "https://dbader.org/blog/python-check-if-file-exists\n",
        "\n",
        "https://datacarpentry.org/python-socialsci/11-joins/index.html\n",
        "\n",
        "https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
        "\n",
        "https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
        "\n",
        "https://www.tutorialspoint.com/matplotlib/matplotlib_bar_plot.htm\n",
        "\n",
        "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.signal.butter.html\n",
        "\n",
        "https://stackoverflow.com/questions/32194967/how-to-do-pca-and-svm-for-classification-in-python\n",
        "\n",
        "https://stackoverflow.com/questions/6822725/rolling-or-sliding-window-iterator\n",
        "\n",
        "https://scikit-learn.org/stable/modules/cross_validation.html\n",
        "\n",
        "https://stackoverflow.com/questions/47684606/merge-cells-with-pandas\n",
        "\n",
        "https://scientificallysound.org/2016/08/18/python-analysing-emg-signals-part-3/\n",
        "\n",
        "https://stackoverflow.com/questions/58374492/python-valueerror-the-length-of-the-input-vector-x-must-be-greater-than-padle\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html\n",
        "\n",
        "https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "https://statinfer.com/204-4-2-calculating-sensitivity-and-specificity-in-python/\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/pandas-multi-index\n",
        "\n",
        "https://www.geeksforgeeks.org/how-to-get-rows-index-names-in-pandas-dataframe/\n",
        "\n",
        "https://stackoverflow.com/questions/28140771/select-only-one-index-of-multiindex-dataframe\n",
        "\n",
        "https://www.educative.io/edpresso/how-to-create-a-confusion-matrix-in-python-using-scikit-learn\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
        "\n",
        "http://www.datasciencemadesimple.com/standard-deviation-function-python-pandas-row-column/\n",
        "\n",
        "https://stackoverflow.com/questions/39047915/concat-series-onto-dataframe-with-column-name\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V77MeC59AHdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "### Combine all files\n",
        "words=['allmorning', 'bird', 'blue', 'cantsleep', 'cat', 'coldrunnynose', 'continuouslyforanhour', 'cost', 'day', 'dollar', 'everymorning', 'everynight', 'gold', 'goodnight', 'happy', 'headache', 'home', 'horse', 'hot', 'hurt', 'itching', 'large', 'mom', 'monthly', 'notfeelgood', 'orange', 'pizza', 'please', 'shirt', 'soreness', 'swelling', 'takeliquidmedicine', 'thatsterrible', 'tired', 'upsetstomach', 'wash']\n",
        "lengths=np.zeros(849, dtype=int)\n",
        "reps=np.zeros(36,dtype=int)\n",
        "wordnum=-1\n",
        "counter=0\n",
        "\n",
        "for w in words:\n",
        "  repcount=0\n",
        "  wordnum+=1\n",
        "\n",
        "  for i in range (10, 120):\n",
        "    path='/content/2MyoASL/' + w + '_' + str(i) + '.csv'\n",
        "\n",
        "    if os.path.exists(path)==True:\n",
        "      counter+=1\n",
        "      repcount+=1\n",
        "      trial=pd.read_csv(path)\n",
        "      lengths[counter-1]=len(trial)\n",
        "      \n",
        "      # Replace counter with evaluated term\n",
        "      for r in range(0,len(trial)):\n",
        "        trial.iloc[r,0]=wordnum\n",
        "        \n",
        "      # Combine all trials\n",
        "      if path=='/content/2MyoASL/allmorning_10.csv':\n",
        "          matrix=trial\n",
        "          \n",
        "          # Create plot for EMG\n",
        "\n",
        "          # Create plot for accelerometer\n",
        "          plt.figure()\n",
        "          alx=plt.axes(projection='3d')\n",
        "          alx.plot3D(trial.loc[:, 'AXL'].values, trial.loc[:, 'AYL'].values, trial.loc[:, 'AZL'].values)\n",
        "          alx.set_title('Accelerometer on left arm')\n",
        "\n",
        "          plt.figure()\n",
        "          arx=plt.axes(projection='3d')\n",
        "          arx.plot3D(trial.loc[:, 'AXR'].values, trial.loc[:, 'AYR'].values, trial.loc[:, 'AZR'].values)\n",
        "          arx.set_title('Accelerometer on right arm')\n",
        "\n",
        "          # Create plot for gyroscope\n",
        "          plt.figure()\n",
        "          glx=plt.axes(projection='3d')\n",
        "          glx.plot3D(trial.loc[:, 'GXL'].values, trial.loc[:, 'GYL'].values, trial.loc[:, 'GZL'].values)\n",
        "          glx.set_title('Gyroscope on left arm')\n",
        "\n",
        "          plt.figure()\n",
        "          grx=plt.axes(projection='3d')\n",
        "          grx.plot3D(trial.loc[:, 'GXR'].values, trial.loc[:, 'GYR'].values, trial.loc[:, 'GZR'].values)\n",
        "          grx.set_title('Gyroscope on right arm')\n",
        "      else:\n",
        "          matrix=pd.concat([matrix, trial])\n",
        "\n",
        "          ###############################################\n",
        "          # Create plot for accelerometer\n",
        "          alx.plot3D(trial.loc[:, 'AXL'].values, trial.loc[:, 'AYL'].values, trial.loc[:, 'AZL'].values)\n",
        "          arx.plot3D(trial.loc[:, 'AXR'].values, trial.loc[:, 'AYR'].values, trial.loc[:, 'AZR'].values)\n",
        "          #plt.show()\n",
        "\n",
        "          # Create plot for gyroscope\n",
        "          glx.plot3D(trial.loc[:, 'GXL'].values, trial.loc[:, 'GYL'].values, trial.loc[:, 'GZL'].values)\n",
        "          grx.plot3D(trial.loc[:, 'GXR'].values, trial.loc[:, 'GYR'].values, trial.loc[:, 'GZR'].values)\n",
        "          ###############################################\n",
        "\n",
        "  reps[wordnum]=repcount\n",
        "plt.show()\n",
        "\"\"\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knhJG10SD22U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "# PCA for normmatrix\n",
        "pca = PCA(n_components=35)\n",
        "comp=pca.fit_transform(norm_matrix_eago)\n",
        "principal=pd.DataFrame(data=comp, columns=['PC 0', 'PC 1', 'PC 2', 'PC 3', 'PC 4', 'PC 5', 'PC 6', 'PC 7', 'PC 8', 'PC 9', 'PC 10', \n",
        "                                           'PC 11', 'PC 12', 'PC 13', 'PC 14', 'PC 16', 'PC 17', 'PC 18', 'PC 19', 'PC 20', \n",
        "                                           'PC 21', 'PC 22', 'PC 23', 'PC 24', 'PC 25', 'PC 26', 'PC 27', 'PC 28', 'PC 29', \n",
        "                                           'PC 30', 'PC 31', 'PC 32', 'PC 33', 'PC 34', 'PC35'])\n",
        "#principal.reset_index(drop=True, inplace=True)\n",
        "#norm_matrix_eago[['Counter']].reset_index(drop=True, inplace=True)\n",
        "norm_matrix_eago.reset_index(drop=True, inplace=True)\n",
        "m.reset_index(drop=True, inplace=True)\n",
        "#finaldf=pd.join([principal, norm_matrix_eago[['Counter']]], axis=1, ignore_index=True).reset_index()\n",
        "finaldf=principal.join(m[['Counter']],how='outer')\n",
        "finaldf=finaldf.drop(columns=['PC 0'])\n",
        "####finaldf=principal\n",
        "####print(m['Counter'])\n",
        "####finaldf['Word']=m['Counter']\n",
        "#finaldf=pd.concat([principal,norm_matrix_eago[['Counter']]], axis=1, ignore_index=True)\n",
        "\n",
        "print(\"Normalized matrix\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn,pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn,pca.singular_values_)\n",
        "plt.show()\n",
        "print(finaldf)\n",
        "#print(principal.join(norm_matrix_eago[['Counter']],how='inner'))\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "# PCA for normalizedmatrix\n",
        "pca = PCA(n_components=34)\n",
        "pca.fit(normalized_matrix)\n",
        "print(\"Normalized features\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn[0:34],pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn[0:34],pca.singular_values_)\n",
        "plt.show()\n",
        "\n",
        "# PCA for standardizedmatrix\n",
        "pca = PCA(n_components=34)\n",
        "pca.fit(standardized_matrix)\n",
        "print(\"Standardized features\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn[0:34],pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn[0:34],pca.singular_values_)\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}