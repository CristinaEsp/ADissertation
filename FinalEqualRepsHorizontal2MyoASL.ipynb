{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalEqualRepsHorizontal2MyoASL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNx3QnPZYFSIBFozp2vc+F7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michelleaeh/Dissertation/blob/master/FinalEqualRepsHorizontal2MyoASL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH79ogCWrzbt",
        "colab_type": "text"
      },
      "source": [
        "**Myo armband dataset from https://data.mendeley.com/datasets/wgswcr8z24/2**\n",
        "\n",
        "\n",
        "**The dataset consits of .csv files collected from two Myo armbands. The format of the files are [word_name]_[id]. The ‘word_name’ is the English translation of the American Sign Language word used and the ‘id’ is a unique identifier. The .zip for each of the above links has sub-folders for each User.**\n",
        "\n",
        "**Each file has 50 columns. They represent a sub-sampled data collection from two Myo devices worn on left and right hands of the signer. The first column is the ‘Counter’ that goes from 1 to 50.**\n",
        "\n",
        "**The following columns are of the format: [Sensor][pod/direction][left/right]. For instance the EMG reading for the first EMG pod (out of 8) on the left hand would be called EMG0R and the accelerometer reading for the Z axis on the left hand would be called: AXL**\n",
        "\n",
        "**If you use this dataset please cite the following papers:**\n",
        "\n",
        "**@inproceedings{paudyal2016sceptre,\n",
        "title={Sceptre: a pervasive, non-invasive, and programmable gesture recognition technology},\n",
        "author={Paudyal, Prajwal and Banerjee, Ayan and Gupta, Sandeep KS},\n",
        "booktitle={Proceedings of the 21st International Conference on Intelligent User Interfaces},\n",
        "pages={282--293},\n",
        "year={2016},\n",
        "organization={ACM}\n",
        "}**\n",
        "\n",
        "**@inproceedings{paudyal2017dyfav,\n",
        "title={Dyfav: Dynamic feature selection and voting for real-time recognition of fingerspelled alphabet using wearables},\n",
        "author={Paudyal, Prajwal and Lee, Junghyo and Banerjee, Ayan and Gupta, Sandeep KS},\n",
        "booktitle={Proceedings of the 22nd International Conference on Intelligent User Interfaces},\n",
        "pages={457--467},\n",
        "year={2017},\n",
        "organization={ACM}\n",
        "}**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHNKWJHfhpMy",
        "colab_type": "text"
      },
      "source": [
        "**Frequency:**\n",
        "\n",
        "50Hz sampling rate\n",
        "\n",
        "**Words:**\n",
        "\n",
        "*36 total words*\n",
        "\n",
        "allmorning, bird, blue, cantsleep, cat, colrunnynose, continuouslyforanhour, cost, day, dollar, everymorning, everynight, gold, goodnight, happy, headache, home, horse, hot, hurt, itching, large, mom, monthly, notfeelgood, orange, pizza, please, shirt, soreness, swelling, takeliquidmedicine, thatsterrible, tired, upsetstomach, wash\n",
        "\n",
        "\n",
        "**Filenames:**\n",
        "\n",
        "*849 total files*\n",
        "\n",
        "(word)_(user#)(try#)\n",
        "\n",
        "\n",
        "**Columns of files:**\n",
        "\n",
        "Counter  (1 -> 50)\n",
        "\n",
        "EMG0L -> EMG7L  (EMG sensor readings)\n",
        "\n",
        "AXL, AYL, AZL  (accelerometer readings)\n",
        "\n",
        "GXL, GYL, GZL  (gyroscope readings)\n",
        "\n",
        "ORL, OPL, OYL  (magnetometer readings?)\n",
        "\n",
        "EMG0R -> EMG7R  (EMG sensor readings)\n",
        "\n",
        "AXR, AYR, AZR  (accelerometer readings)\n",
        "\n",
        "GXR, GYR, GZR  (gyroscope readings)\n",
        "\n",
        "ORR, OPR, OYR  (magnetometer readings?)\n",
        "\n",
        "features=['EMG0L', 'EMG1L', 'EMG2L', 'EMG3L', 'EMG4L', 'EMG5L', 'EMG6L', 'EMG7L', 'AXL', 'AYL', 'AZL', 'GXL', 'GYL', 'GZL', 'ORL', 'OPL', 'OYL', 'EMG0R', 'EMG1R', 'EMG2R', 'EMG3R', 'EMG4R', 'EMG5R', 'EMG6R', 'EMG7R', 'AXR', 'AYR', 'AZR', 'GXR', 'GYR', 'GZR', 'ORR', 'OPR', 'OYR']\n",
        "\n",
        "\n",
        "**Size of files:**\n",
        "\n",
        "All files are 50 rows x 35 columns except continuouslyforanhour_22.csv, headache_52.csv, home_61.csv, and mom_82.csv which are 101 rows x 35 columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVqdAdxkr-U5",
        "colab_type": "text"
      },
      "source": [
        "**Steps:**\n",
        "\n",
        "1. Combine files\n",
        "2. Normalize or standardize matrix\n",
        "3. Apply Butterworth\n",
        "4. Apply PCA\n",
        "5. Input to SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TnTycFtrpHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import warnings\n",
        "\n",
        "from google.colab import files\n",
        "from mpl_toolkits import mplot3d\n",
        "from scipy import signal\n",
        "from scipy.io import loadmat\n",
        "from sklearn import metrics\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Extract all files from zip\n",
        "with ZipFile(\"/content/2MyoASL.zip\", 'r') as zip:\n",
        "  zip.extractall()\n",
        "\n",
        "# Generate matrices for all combinations of sensors (E=3, A=5, G=7, O=11)\n",
        "products=[3, 5, 7, 11, 15, 21, 33, 35, 55, 77, 105, 165, 231, 385, 1155]\n",
        "comb=['e', 'a', 'g', 'o', 'ea', 'eg', 'eo', 'ag', 'ao', 'go', 'eag', 'eao', 'ego', 'ago', 'eago']\n",
        "emg=['EMG0L', 'EMG1L', 'EMG2L', 'EMG3L', 'EMG4L', 'EMG5L', 'EMG6L', 'EMG7L', \n",
        "     'EMG0R', 'EMG1R', 'EMG2R', 'EMG3R', 'EMG4R', 'EMG5R', 'EMG6R', 'EMG7R']\n",
        "acc=['AXL', 'AYL', 'AZL', 'AXR', 'AYR', 'AZR']\n",
        "gyro=['GXL', 'GYL', 'GZL', 'GXR', 'GYR', 'GZR']\n",
        "ori=['ORL', 'OPL', 'OYL', 'ORR', 'OPR', 'OYR']\n",
        "\n",
        "# Initialization of counters\n",
        "words=['allmorning', 'bird', 'blue', 'cantsleep', 'cat', 'coldrunnynose', 'continuouslyforanhour', 'cost', 'day', \n",
        "       'dollar', 'everymorning', 'everynight', 'gold', 'goodnight', 'happy', 'headache', 'home', 'horse', 'hot', \n",
        "       'hurt', 'itching', 'large', 'mom', 'monthly', 'notfeelgood', 'orange', 'pizza', 'please', 'shirt', \n",
        "       'soreness', 'swelling', 'takeliquidmedicine', 'thatsterrible', 'tired', 'upsetstomach', 'wash']\n",
        "colnames=emg[:8]+acc[:3]+gyro[:3]+ori[:3]+emg[8:]+acc[3:]+gyro[3:]+ori[3:]\n",
        "lengths=np.zeros(849, dtype=int)\n",
        "reps=np.zeros(36,dtype=int)\n",
        "repsum=np.zeros(37,dtype=int)\n",
        "headers=np.empty(1701, dtype=object)\n",
        "features=np.zeros(15)\n",
        "target=np.zeros(15)\n",
        "matrix=np.zeros(1)\n",
        "\n",
        "fn=np.arange(1701)\n",
        "wordnum=-1\n",
        "counter=-1\n",
        "start=0\n",
        "num=0\n",
        "n=0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQFtofv7yG7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "db9155c7-10a0-4106-b238-33503d264e3a"
      },
      "source": [
        "# Combine all files\n",
        "for w in words:\n",
        "  repcount=0\n",
        "  wordnum+=1\n",
        "\n",
        "  for i in range (10, 120):\n",
        "    path='/content/2MyoASL/' + w + '_' + str(i) + '.csv'\n",
        "\n",
        "    if os.path.exists(path)==True:\n",
        "      counter+=1\n",
        "      repcount+=1\n",
        "      trial=pd.read_csv(path)\n",
        "\n",
        "      trial.reset_index(drop=True)\n",
        "      \n",
        "      # Assign word number to one row\n",
        "      row=np.zeros(1)\n",
        "      for t in range(35):\n",
        "        if t==0:\n",
        "          row[0]=wordnum\n",
        "        else:\n",
        "          sensor=trial.iloc[0:50,t].values\n",
        "          sensor.reshape([1,50])\n",
        "          row=np.concatenate((row, sensor))\n",
        "      prev=row\n",
        "      \n",
        "      # Combine all trials\n",
        "      if counter==0:\n",
        "        matrix=prev\n",
        "      else:\n",
        "        matrix=np.concatenate([matrix,prev])\n",
        "\n",
        "  reps[wordnum]=repcount\n",
        "  if wordnum>0:\n",
        "    repsum[wordnum]=reps[wordnum-1]+repsum[wordnum-1]\n",
        "    repsum[36]=849\n",
        "\n",
        "# Create header name array\n",
        "headers[0]='Word'\n",
        "for c in colnames:\n",
        "  for t in range(50):\n",
        "    num+=1\n",
        "    headers[num]=c\n",
        "\n",
        "# Give format to final matrix \n",
        "matrix=matrix.reshape([849,1701])\n",
        "matrix=pd.DataFrame(matrix, columns=headers)\n",
        "print(matrix)\n",
        "matrix.to_csv(path_or_buf='/content/matrix.csv')\n",
        "print('Reps:',reps)\n",
        "print('Cummulative reps:',repsum)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Word  EMG0L  EMG0L  EMG0L  EMG0L  ...    OYR    OYR    OYR    OYR    OYR\n",
            "0     0.0    0.0    0.0   -3.0   -1.0  ...   83.0   83.0   83.0   83.0   83.0\n",
            "1     0.0    0.0    0.0    4.0   -2.0  ...   83.0   83.0   83.0   83.0   83.0\n",
            "2     0.0    0.0    0.0   -8.0   -1.0  ...   84.0   84.0   84.0   84.0   84.0\n",
            "3     0.0    0.0    0.0   -1.0  -19.0  ...   83.0   83.0   83.0   83.0   83.0\n",
            "4     0.0    0.0    0.0    1.0  -16.0  ...   93.0   91.0   91.0   91.0   91.0\n",
            "..    ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
            "844  35.0    0.0    0.0   -2.0    0.0  ...  106.0  104.0  100.0   98.0   95.0\n",
            "845  35.0    0.0    0.0    2.0   -8.0  ...  176.0  176.0  177.0  177.0  177.0\n",
            "846  35.0    0.0    0.0   -8.0   26.0  ...  177.0  176.0  175.0  175.0  176.0\n",
            "847  35.0    0.0    0.0   -1.0   21.0  ...  178.0  178.0  179.0  179.0  179.0\n",
            "848  35.0    0.0    0.0    8.0  -19.0  ...  179.0  179.0  179.0  179.0    0.0\n",
            "\n",
            "[849 rows x 1701 columns]\n",
            "Reps: [19 24 32 20 24 20 19 31 24 29 20 21 23 33 34 18 27 24 35 19 17 34 30 19\n",
            " 22 21 23 27 27  4 20 19 20 20 21 29]\n",
            "Cummulative reps: [  0  19  43  75  95 119 139 158 189 213 242 262 283 306 339 373 391 418\n",
            " 442 477 496 513 547 577 596 618 639 662 689 716 720 740 759 779 799 820\n",
            " 849]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaytNKUWGo7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "8df863a0-8b36-46c8-b36d-4a55e094db6e"
      },
      "source": [
        "# Average and standard deviation of each sensor in each file\n",
        "for s in colnames:\n",
        "  avg=matrix[s].mean(axis=1)\n",
        "  sd=matrix[s].std(axis=1)\n",
        "  sensor=pd.concat([avg.rename(s+': Mean_'),sd.rename('St. dev.')], axis=1)\n",
        "  if s=='EMG0L':\n",
        "    asd=sensor\n",
        "  else:\n",
        "    asd=pd.concat([asd, sensor], axis=1)\n",
        "print(asd)\n",
        "\n",
        "# Average and standard deviation of each file\n",
        "avg=matrix.mean(axis=1)\n",
        "sd=matrix.std(axis=1)\n",
        "pd.concat([avg.rename('Mean'),sd.rename('St. dev.')], axis=1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     EMG0L: Mean_   St. dev.  EMG1L: Mean_  ...   St. dev.  OYR: Mean_   St. dev.\n",
            "0           -2.32   8.664825         -0.80  ...  28.427609       86.70  10.529356\n",
            "1           -1.80   9.544739         -4.08  ...  27.821010       85.68   6.579002\n",
            "2           -3.16  13.085839         -2.32  ...  30.345736       91.88  17.358924\n",
            "3           -0.82  10.123099         -3.16  ...  29.645002       88.46  12.969682\n",
            "4           -0.50   6.516071          2.76  ...  13.237239      116.58  18.099600\n",
            "..            ...        ...           ...  ...        ...         ...        ...\n",
            "844          0.56   7.754288          0.22  ...  17.236281      104.76   7.528341\n",
            "845         -1.74   6.520955         -1.20  ...  21.772891       69.66  85.251036\n",
            "846          1.02   7.731436          0.46  ...  22.707735       56.76  79.408415\n",
            "847          0.06   5.582078          2.36  ...  23.650422       71.62  84.238701\n",
            "848         -2.22   7.434860         -1.62  ...  25.101622       58.52  79.668763\n",
            "\n",
            "[849 rows x 68 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean</th>\n",
              "      <th>St. dev.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.256437</td>\n",
              "      <td>46.545832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.220110</td>\n",
              "      <td>47.316822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15.441784</td>\n",
              "      <td>45.614456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.651092</td>\n",
              "      <td>47.038916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15.063294</td>\n",
              "      <td>49.105612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>844</th>\n",
              "      <td>13.167964</td>\n",
              "      <td>41.642351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>13.815314</td>\n",
              "      <td>42.880121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>12.970618</td>\n",
              "      <td>42.725653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>13.852317</td>\n",
              "      <td>43.758631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>13.144035</td>\n",
              "      <td>44.761750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>849 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Mean   St. dev.\n",
              "0    15.256437  46.545832\n",
              "1    14.220110  47.316822\n",
              "2    15.441784  45.614456\n",
              "3    13.651092  47.038916\n",
              "4    15.063294  49.105612\n",
              "..         ...        ...\n",
              "844  13.167964  41.642351\n",
              "845  13.815314  42.880121\n",
              "846  12.970618  42.725653\n",
              "847  13.852317  43.758631\n",
              "848  13.144035  44.761750\n",
              "\n",
              "[849 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLze9It2KrBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f51fbc19-6c63-4681-d8b4-3de23f4e8f74"
      },
      "source": [
        "# Ensure all words have same number of repetitions\n",
        "numreps=20\n",
        "\n",
        "for i in range(len(reps)-1,-1,-1):\n",
        "  tl=sd.iloc[repsum[i]:repsum[i+1]]\n",
        "  u=repsum[i+1]-1\n",
        "  if reps[i]<numreps:\n",
        "    for r in range(len(matrix)-1,-1,-1):\n",
        "      if int(matrix.iloc[r]['Word'])==i:\n",
        "        matrix=matrix.drop(r)\n",
        "  elif reps[i]>numreps:\n",
        "    while reps[i]>numreps:\n",
        "      if tl[u]==tl.max():\n",
        "        tl[u]=0\n",
        "        matrix=matrix.drop(u)\n",
        "        reps[i]=reps[i]-1\n",
        "        u=repsum[i+1]-1\n",
        "      else:\n",
        "        u-=1\n",
        "\n",
        "print(matrix)\n",
        "print('reps',reps)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Word  EMG0L  EMG0L  EMG0L  EMG0L  ...    OYR    OYR    OYR    OYR    OYR\n",
            "23    1.0    0.0    0.0   -1.0   -1.0  ...  170.0  170.0  170.0  170.0  170.0\n",
            "24    1.0    0.0    0.0    0.0   -2.0  ...  178.0  179.0  179.0  179.0  179.0\n",
            "25    1.0    0.0    0.0   -1.0   -1.0  ...  177.0  177.0  177.0  177.0  177.0\n",
            "26    1.0    0.0    0.0   -1.0   -1.0  ...  179.0  179.0  179.0    0.0    0.0\n",
            "27    1.0    0.0    0.0   -1.0    0.0  ...   68.0   64.0   61.0   58.0   57.0\n",
            "..    ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
            "842  35.0    0.0    0.0   -1.0   -4.0  ...  103.0  102.0  100.0   97.0   95.0\n",
            "843  35.0    0.0    0.0    7.0    6.0  ...  100.0   98.0   95.0   94.0   92.0\n",
            "844  35.0    0.0    0.0   -2.0    0.0  ...  106.0  104.0  100.0   98.0   95.0\n",
            "845  35.0    0.0    0.0    2.0   -8.0  ...  176.0  176.0  177.0  177.0  177.0\n",
            "846  35.0    0.0    0.0   -8.0   26.0  ...  177.0  176.0  175.0  175.0  176.0\n",
            "\n",
            "[560 rows x 1701 columns]\n",
            "reps [19 20 20 20 20 20 19 20 20 20 20 20 20 20 20 18 20 20 20 19 17 20 20 19\n",
            " 20 20 20 20 20  4 20 19 20 20 20 20]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cry7YARuOhoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attempt=matrix\n",
        "attempt.to_csv(path_or_buf='/content/attempt.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7Ib41KW5f32",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "8f889f95-bb53-4445-bcfa-87a7bbe136da"
      },
      "source": [
        "# Eliminate unnecessary columns to create combinatory matrices\n",
        "for v in products:\n",
        "  m=matrix\n",
        "  if v%3!=0:\n",
        "    m=m.drop(emg,1)\n",
        "  if v%5!=0:\n",
        "    m=m.drop(acc,1)\n",
        "  if v%7!=0:\n",
        "    m=m.drop(gyro,1)\n",
        "  if v%11!=0:\n",
        "    m=m.drop(ori,1)\n",
        "  products[n]=m\n",
        "  exec(comb[n]+\"=products[n]\")\n",
        "  n+=1\n",
        "  \n",
        "  # Normalize and Standardize each of the 15 matrices\n",
        "  # Separate features from target values\n",
        "  x = m.iloc[:, m.columns!='Word']   # Features\n",
        "  wordcol=np.empty(len(m), dtype=object)\n",
        "  z=0\n",
        "  #wcol=m.iloc[:,m.columns['Word']].values\n",
        "  #wcol=m['Word'].tolist()\n",
        "  wcol=[int(i) for i in m['Word'].values]\n",
        "  for f in wcol:\n",
        "    wordcol[z]=words[f]\n",
        "    z+=1\n",
        "  wordcol=np.asmatrix(wordcol)\n",
        " \n",
        "  ## Normalize features so that each column is between 0 and 1\n",
        "  norm_matrix=(m-m.min())/(m.max()-m.min())\n",
        "  norm_matrix=np.concatenate((np.transpose(wordcol),norm_matrix.iloc[:,1:]),axis=1)\n",
        "  exec(\"norm_matrix_\"+comb[n-1]+\"=pd.DataFrame(norm_matrix)\")\n",
        "  exec(\"norm_matrix_\"+comb[n-1]+\"=norm_matrix_\"+comb[n-1]+\".dropna(axis=1)\")\n",
        "\n",
        " # Standardize features with mean=0 and deviation=1\n",
        "  standardized_matrix=StandardScaler().fit_transform(x)\n",
        "  standardized_matrix=np.concatenate((np.transpose(wordcol),standardized_matrix),axis=1)\n",
        "  exec(\"standardized_matrix_\"+comb[n-1]+\"=pd.DataFrame(standardized_matrix,columns=m.columns)\")\n",
        "  exec(\"standardized_matrix_\"+comb[n-1]+\"=standardized_matrix_\"+comb[n-1]+\".dropna(axis=1)\")\n",
        "\n",
        "print(norm_matrix_eago)\n",
        "print(standardized_matrix_eago)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "n=0\n",
        "for m in products:\n",
        "  # Separate features from target values\n",
        "  print(m)\n",
        "  x = m.iloc[:, m.columns!='Word']   # Features\n",
        "  print(m)\n",
        "  print(x)\n",
        " \n",
        "  # Normalize features so that each column is between 0 and 1\n",
        "  norm_matrix=(m-m.min())/(m.max()-m.min())\n",
        "  norm_matrix=pd.DataFrame(norm_matrix)\n",
        "  norm_matrix=norm_matrix.dropna(axis=1)\n",
        "  for r in range(849):\n",
        "    wn=int(35*norm_matrix.iloc[r,0])\n",
        "    norm_matrix.iloc[r,0]=words[wn]\n",
        "  norm[n]=norm_matrix\n",
        "\n",
        "  # Standardize features with mean=0 and deviation=1\n",
        "  standardized_matrix=StandardScaler().fit_transform(x)\n",
        "  standardized_matrix=pd.DataFrame(standardized_matrix)\n",
        "  standardized_matrix=standardized_matrix.dropna(axis=1)\n",
        "  stand[n]=standardized_matrix\n",
        "\n",
        "  n+=1\n",
        "\n",
        "cm=norm+stand ####### cm stores all 15 matrices normalized first and then standardized\n",
        "\n",
        "print(m)\n",
        "print(products[14])\n",
        "print(norm[14])\n",
        "print(stand[14])\n",
        "\"\"\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     0         2         3         4     ...      1697      1698      1699      1700\n",
            "0    bird  0.321429  0.507812  0.574074  ...  0.949721  0.949721  0.949721  0.949721\n",
            "1    bird  0.321429  0.515625  0.564815  ...         1         1         1         1\n",
            "2    bird  0.321429  0.507812  0.574074  ...  0.988827  0.988827  0.988827  0.988827\n",
            "3    bird  0.321429  0.507812  0.574074  ...         1         1         0         0\n",
            "4    bird  0.321429  0.507812  0.583333  ...  0.357542  0.340782  0.324022  0.318436\n",
            "..    ...       ...       ...       ...  ...       ...       ...       ...       ...\n",
            "555  wash  0.321429  0.507812  0.546296  ...  0.569832  0.558659  0.541899  0.530726\n",
            "556  wash  0.321429  0.570312  0.638889  ...  0.547486  0.530726   0.52514  0.513966\n",
            "557  wash  0.321429       0.5  0.583333  ...  0.581006  0.558659  0.547486  0.530726\n",
            "558  wash  0.321429   0.53125  0.509259  ...   0.98324  0.988827  0.988827  0.988827\n",
            "559  wash  0.321429  0.453125  0.824074  ...   0.98324  0.977654  0.977654   0.98324\n",
            "\n",
            "[560 rows x 1693 columns]\n",
            "     Word EMG0L       EMG0L      EMG0L  ...       OYR       OYR       OYR       OYR\n",
            "0    bird     0 -0.00744137 -0.0148686  ...   2.01986   2.02131    2.0241   2.02481\n",
            "1    bird     0 -0.00744137   0.105804  ...   2.21771   2.21945   2.22277   2.22394\n",
            "2    bird     0 -0.00744137 -0.0148686  ...   2.17374   2.17542   2.17862   2.17969\n",
            "3    bird     0 -0.00744137 -0.0148686  ...   2.21771   2.21945  -1.72854  -1.73654\n",
            "4    bird     0 -0.00744137 -0.0148686  ...  -0.31031 -0.378394 -0.448228 -0.475384\n",
            "..    ...   ...         ...        ...  ...       ...       ...       ...       ...\n",
            "555  wash     0 -0.00744137 -0.0148686  ...  0.525034  0.480216  0.412673  0.365388\n",
            "556  wash     0 -0.00744137   0.950513  ...  0.437103  0.370138  0.346449  0.299012\n",
            "557  wash     0 -0.00744137  -0.135541  ...     0.569  0.480216  0.434747  0.365388\n",
            "558  wash     0 -0.00744137    0.34715  ...   2.15176   2.17542   2.17862   2.17969\n",
            "559  wash     0 -0.00744137  -0.859578  ...   2.15176   2.13139   2.13447   2.15756\n",
            "\n",
            "[560 rows x 1701 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n\\nn=0\\nfor m in products:\\n  # Separate features from target values\\n  print(m)\\n  x = m.iloc[:, m.columns!='Word']   # Features\\n  print(m)\\n  print(x)\\n \\n  # Normalize features so that each column is between 0 and 1\\n  norm_matrix=(m-m.min())/(m.max()-m.min())\\n  norm_matrix=pd.DataFrame(norm_matrix)\\n  norm_matrix=norm_matrix.dropna(axis=1)\\n  for r in range(849):\\n    wn=int(35*norm_matrix.iloc[r,0])\\n    norm_matrix.iloc[r,0]=words[wn]\\n  norm[n]=norm_matrix\\n\\n  # Standardize features with mean=0 and deviation=1\\n  standardized_matrix=StandardScaler().fit_transform(x)\\n  standardized_matrix=pd.DataFrame(standardized_matrix)\\n  standardized_matrix=standardized_matrix.dropna(axis=1)\\n  stand[n]=standardized_matrix\\n\\n  n+=1\\n\\ncm=norm+stand ####### cm stores all 15 matrices normalized first and then standardized\\n\\nprint(m)\\nprint(products[14])\\nprint(norm[14])\\nprint(stand[14])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IaWFWIUrT5i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7b9fe916-7e65-4a4c-cee4-579fa69eb166"
      },
      "source": [
        "\"\"\"\n",
        "# Replace wordnum with word\n",
        "for r in range(len(matrix)):\n",
        "  wn=int(35*norm_matrix_eago.iloc[r,0])\n",
        "  norm_matrix_eago.iloc[r,0]=words[wn]\n",
        "nmatrix=norm_matrix_eago\n",
        "print(nmatrix)\n",
        "nmatrix.to_csv(path_or_buf='/content/nmatrix.csv')\n",
        "words=set(nmatrix['Word'])\n",
        "\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# Replace wordnum with word\\nfor r in range(len(matrix)):\\n  wn=int(35*norm_matrix_eago.iloc[r,0])\\n  norm_matrix_eago.iloc[r,0]=words[wn]\\nnmatrix=norm_matrix_eago\\nprint(nmatrix)\\nnmatrix.to_csv(path_or_buf='/content/nmatrix.csv')\\nwords=set(nmatrix['Word'])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJjGC_1Q5r03",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "51f5a03b-2924-4fea-d413-3dcfcfb5b13e"
      },
      "source": [
        "# Butterworth\n",
        "#high = 20/(1000/2)\n",
        "#low = 450/(1000/2)\n",
        "high = 1/(50/2)\n",
        "low = 23/(50/2)\n",
        "\n",
        "b, a = sp.signal.butter(4, [high,low], btype='bandpass')\n",
        "\n",
        "for r in emg:\n",
        "  norm_matrix_eago[[r]]\n",
        "  # process EMG signal: filter EMG\n",
        "  emg_filtered = sp.signal.lfilter(b, a, norm_matrix_eago[[r]])\n",
        "  norm_matrix_eago[[r]]=emg_filtered"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-845faf9b5b04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mnorm_matrix_eago\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;31m# process EMG signal: filter EMG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0memg_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_matrix_eago\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         )\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1638\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['EMG0L'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oegUzb00nsA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "buttermatrix=norm_matrix_eago"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I16C6HCyrFZr",
        "colab_type": "text"
      },
      "source": [
        "**Combinations of steps for classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw8kyulNOsmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directly to SVM\n",
        "x = attempt.iloc[:, attempt.columns!='Word'].values   # Features\n",
        "y = attempt.loc[:,'Word'].values     # Target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(x_train, y_train)\n",
        "print ('score', clf.score(x_test, y_test))\n",
        "y_pred=clf.predict(x_test)\n",
        "print ('pred label', y_pred)\n",
        "print('length',len(clf.predict(x_test)))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, x_test, y_test,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.figure(figsize=(50,50))\n",
        "plt.show()\n",
        "\n",
        "#print(classification_report(y_test, y_pred, target_names=words))\n",
        "directresults=classification_report(y_test, y_pred, target_names=words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgPwhYZvrn3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalized to SVM\n",
        "x = nmatrix.iloc[:, nmatrix.columns!='Word'].values   # Features\n",
        "y = nmatrix.loc[:,'Word'].values     # Target\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(x_train, y_train)\n",
        "print ('score', clf.score(x_test, y_test))\n",
        "y_pred=clf.predict(x_test)\n",
        "print ('pred label', y_pred)\n",
        "print('length',len(clf.predict(x_test)))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, x_test, y_test,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.figure(figsize=(50,50))\n",
        "plt.show()\n",
        "\n",
        "#print(classification_report(y_test, y_pred, target_names=words))\n",
        "normresults=classification_report(y_test, y_pred, target_names=words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OL74iKMnWZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalized, Butterworth to SVM\n",
        "x = buttermatrix.iloc[:, buttermatrix.columns!='Word'].values   # Features\n",
        "y = buttermatrix.loc[:,'Word'].values     # Target\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(x_train, y_train)\n",
        "print ('score', clf.score(x_test, y_test))\n",
        "y_pred=clf.predict(x_test)\n",
        "print ('pred label', y_pred)\n",
        "print('length',len(clf.predict(x_test)))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, x_test, y_test,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.figure(figsize=(50,50))\n",
        "plt.show()\n",
        "\n",
        "#print(classification_report(y_test, y_pred, target_names=words))\n",
        "butterresults=classification_report(y_test, y_pred, target_names=words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riv-kFwa9oMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PCA for norm_matrix\n",
        "\n",
        "x = norm_matrix_eago.iloc[:, norm_matrix_eago.columns!='Word'].values   # Features\n",
        "y = norm_matrix_eago.loc[:,'Word'].values     # Target\n",
        "print(y)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)\n",
        "\n",
        "pca = PCA(n_components=40)\n",
        "pca.fit(x_train)\n",
        "x_t_train = pca.transform(x_train)\n",
        "x_t_test = pca.transform(x_test)\n",
        "\n",
        "#### plot\n",
        "print(\"Normalized matrix\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn[:40],pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn[:40],pca.singular_values_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSevZSPDFZjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalized, Butterworth, PCA to SVM\n",
        "clf = SVC()\n",
        "clf.fit(x_t_train, y_train)\n",
        "print ('score', clf.score(x_t_test, y_test))\n",
        "y_pred=clf.predict(x_t_test)\n",
        "print ('pred label', y_pred)\n",
        "print('length',len(clf.predict(x_t_test)))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(clf, x_t_test, y_test,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.figure(figsize=(50,50))\n",
        "plt.show()\n",
        "\n",
        "#print(classification_report(y_test, y_pred, target_names=words))\n",
        "pcaresults=classification_report(y_test, y_pred, target_names=words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPsmjnnASPYX",
        "colab_type": "text"
      },
      "source": [
        "**Summary of results**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGL1j6iBSlGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Directly:')\n",
        "print(directresults)\n",
        "print('Normalized:')\n",
        "print(normresults)\n",
        "print('Butterworth:')\n",
        "print(butterresults)\n",
        "print('PCA:')\n",
        "print(pcaresults)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h57zKLByfy2Y",
        "colab_type": "text"
      },
      "source": [
        "TODO:\n",
        "\n",
        "-check what happens when combining diff data sources\n",
        "\n",
        "-graph components\n",
        "\n",
        "find correlations\n",
        "\n",
        "-interpret pca results\n",
        "\n",
        "-try pca per individual/word\n",
        "\n",
        "-read dataset papers\n",
        "\n",
        "correlation component with word\n",
        "\n",
        "-try straight to svm\n",
        "\n",
        "-resend email\n",
        "\n",
        "check what is the data\n",
        "\n",
        "-merge timeseries word index\n",
        "\n",
        "see how stable each feature are\n",
        "\n",
        "standard deviation timeseries\n",
        "\n",
        "-try without filter\n",
        "\n",
        "multi-class classifier SVM\n",
        "\n",
        "**try with 2 words, only emg\n",
        "average per column\n",
        "test each step\n",
        "test svm with 2 matrices\n",
        "see if svm has access to test set \n",
        "maybe shifted per set \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScbnguG8ONoC",
        "colab_type": "text"
      },
      "source": [
        "https://www.researchgate.net/publication/303707429_Combining_Smartphone_and_Smartwatch_Sensor_Data_in_Activity_Recognition_Approaches_an_Experimental_Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay3NExQ59xrM",
        "colab_type": "text"
      },
      "source": [
        "References\n",
        "\n",
        "https://stackoverflow.com/questions/56449262/how-to-upload-folders-to-google-colab\n",
        "\n",
        "https://github.com/datarail/datarail/issues/39\n",
        "\n",
        "https://dbader.org/blog/python-check-if-file-exists\n",
        "\n",
        "https://datacarpentry.org/python-socialsci/11-joins/index.html\n",
        "\n",
        "https://stackoverflow.com/questions/26414913/normalize-columns-of-pandas-data-frame\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
        "\n",
        "https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
        "\n",
        "https://www.tutorialspoint.com/matplotlib/matplotlib_bar_plot.htm\n",
        "\n",
        "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.signal.butter.html\n",
        "\n",
        "https://stackoverflow.com/questions/32194967/how-to-do-pca-and-svm-for-classification-in-python\n",
        "\n",
        "https://stackoverflow.com/questions/6822725/rolling-or-sliding-window-iterator\n",
        "\n",
        "https://scikit-learn.org/stable/modules/cross_validation.html\n",
        "\n",
        "https://stackoverflow.com/questions/47684606/merge-cells-with-pandas\n",
        "\n",
        "https://scientificallysound.org/2016/08/18/python-analysing-emg-signals-part-3/\n",
        "\n",
        "https://stackoverflow.com/questions/58374492/python-valueerror-the-length-of-the-input-vector-x-must-be-greater-than-padle\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html\n",
        "\n",
        "https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "https://statinfer.com/204-4-2-calculating-sensitivity-and-specificity-in-python/\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/pandas-multi-index\n",
        "\n",
        "https://www.geeksforgeeks.org/how-to-get-rows-index-names-in-pandas-dataframe/\n",
        "\n",
        "https://stackoverflow.com/questions/28140771/select-only-one-index-of-multiindex-dataframe\n",
        "\n",
        "https://www.educative.io/edpresso/how-to-create-a-confusion-matrix-in-python-using-scikit-learn\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
        "\n",
        "http://www.datasciencemadesimple.com/standard-deviation-function-python-pandas-row-column/\n",
        "\n",
        "https://stackoverflow.com/questions/39047915/concat-series-onto-dataframe-with-column-name\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V77MeC59AHdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "### Combine all files\n",
        "words=['allmorning', 'bird', 'blue', 'cantsleep', 'cat', 'coldrunnynose', 'continuouslyforanhour', 'cost', 'day', 'dollar', 'everymorning', 'everynight', 'gold', 'goodnight', 'happy', 'headache', 'home', 'horse', 'hot', 'hurt', 'itching', 'large', 'mom', 'monthly', 'notfeelgood', 'orange', 'pizza', 'please', 'shirt', 'soreness', 'swelling', 'takeliquidmedicine', 'thatsterrible', 'tired', 'upsetstomach', 'wash']\n",
        "lengths=np.zeros(849, dtype=int)\n",
        "reps=np.zeros(36,dtype=int)\n",
        "wordnum=-1\n",
        "counter=0\n",
        "\n",
        "for w in words:\n",
        "  repcount=0\n",
        "  wordnum+=1\n",
        "\n",
        "  for i in range (10, 120):\n",
        "    path='/content/2MyoASL/' + w + '_' + str(i) + '.csv'\n",
        "\n",
        "    if os.path.exists(path)==True:\n",
        "      counter+=1\n",
        "      repcount+=1\n",
        "      trial=pd.read_csv(path)\n",
        "      lengths[counter-1]=len(trial)\n",
        "      \n",
        "      # Replace counter with evaluated term\n",
        "      for r in range(0,len(trial)):\n",
        "        trial.iloc[r,0]=wordnum\n",
        "        \n",
        "      # Combine all trials\n",
        "      if path=='/content/2MyoASL/allmorning_10.csv':\n",
        "          matrix=trial\n",
        "          \n",
        "          # Create plot for EMG\n",
        "\n",
        "          # Create plot for accelerometer\n",
        "          plt.figure()\n",
        "          alx=plt.axes(projection='3d')\n",
        "          alx.plot3D(trial.loc[:, 'AXL'].values, trial.loc[:, 'AYL'].values, trial.loc[:, 'AZL'].values)\n",
        "          alx.set_title('Accelerometer on left arm')\n",
        "\n",
        "          plt.figure()\n",
        "          arx=plt.axes(projection='3d')\n",
        "          arx.plot3D(trial.loc[:, 'AXR'].values, trial.loc[:, 'AYR'].values, trial.loc[:, 'AZR'].values)\n",
        "          arx.set_title('Accelerometer on right arm')\n",
        "\n",
        "          # Create plot for gyroscope\n",
        "          plt.figure()\n",
        "          glx=plt.axes(projection='3d')\n",
        "          glx.plot3D(trial.loc[:, 'GXL'].values, trial.loc[:, 'GYL'].values, trial.loc[:, 'GZL'].values)\n",
        "          glx.set_title('Gyroscope on left arm')\n",
        "\n",
        "          plt.figure()\n",
        "          grx=plt.axes(projection='3d')\n",
        "          grx.plot3D(trial.loc[:, 'GXR'].values, trial.loc[:, 'GYR'].values, trial.loc[:, 'GZR'].values)\n",
        "          grx.set_title('Gyroscope on right arm')\n",
        "      else:\n",
        "          matrix=pd.concat([matrix, trial])\n",
        "\n",
        "          ###############################################\n",
        "          # Create plot for accelerometer\n",
        "          alx.plot3D(trial.loc[:, 'AXL'].values, trial.loc[:, 'AYL'].values, trial.loc[:, 'AZL'].values)\n",
        "          arx.plot3D(trial.loc[:, 'AXR'].values, trial.loc[:, 'AYR'].values, trial.loc[:, 'AZR'].values)\n",
        "          #plt.show()\n",
        "\n",
        "          # Create plot for gyroscope\n",
        "          glx.plot3D(trial.loc[:, 'GXL'].values, trial.loc[:, 'GYL'].values, trial.loc[:, 'GZL'].values)\n",
        "          grx.plot3D(trial.loc[:, 'GXR'].values, trial.loc[:, 'GYR'].values, trial.loc[:, 'GZR'].values)\n",
        "          ###############################################\n",
        "\n",
        "  reps[wordnum]=repcount\n",
        "plt.show()\n",
        "\"\"\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knhJG10SD22U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "# PCA for normmatrix\n",
        "pca = PCA(n_components=35)\n",
        "comp=pca.fit_transform(norm_matrix_eago)\n",
        "principal=pd.DataFrame(data=comp, columns=['PC 0', 'PC 1', 'PC 2', 'PC 3', 'PC 4', 'PC 5', 'PC 6', 'PC 7', 'PC 8', 'PC 9', 'PC 10', \n",
        "                                           'PC 11', 'PC 12', 'PC 13', 'PC 14', 'PC 16', 'PC 17', 'PC 18', 'PC 19', 'PC 20', \n",
        "                                           'PC 21', 'PC 22', 'PC 23', 'PC 24', 'PC 25', 'PC 26', 'PC 27', 'PC 28', 'PC 29', \n",
        "                                           'PC 30', 'PC 31', 'PC 32', 'PC 33', 'PC 34', 'PC35'])\n",
        "#principal.reset_index(drop=True, inplace=True)\n",
        "#norm_matrix_eago[['Counter']].reset_index(drop=True, inplace=True)\n",
        "norm_matrix_eago.reset_index(drop=True, inplace=True)\n",
        "m.reset_index(drop=True, inplace=True)\n",
        "#finaldf=pd.join([principal, norm_matrix_eago[['Counter']]], axis=1, ignore_index=True).reset_index()\n",
        "finaldf=principal.join(m[['Counter']],how='outer')\n",
        "finaldf=finaldf.drop(columns=['PC 0'])\n",
        "####finaldf=principal\n",
        "####print(m['Counter'])\n",
        "####finaldf['Word']=m['Counter']\n",
        "#finaldf=pd.concat([principal,norm_matrix_eago[['Counter']]], axis=1, ignore_index=True)\n",
        "\n",
        "print(\"Normalized matrix\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn,pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn,pca.singular_values_)\n",
        "plt.show()\n",
        "print(finaldf)\n",
        "#print(principal.join(norm_matrix_eago[['Counter']],how='inner'))\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "# PCA for normalizedmatrix\n",
        "pca = PCA(n_components=34)\n",
        "pca.fit(normalized_matrix)\n",
        "print(\"Normalized features\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn[0:34],pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn[0:34],pca.singular_values_)\n",
        "plt.show()\n",
        "\n",
        "# PCA for standardizedmatrix\n",
        "pca = PCA(n_components=34)\n",
        "pca.fit(standardized_matrix)\n",
        "print(\"Standardized features\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "plt.figure()\n",
        "plt.bar(fn[0:34],pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "plt.bar(fn[0:34],pca.singular_values_)\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}